{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to answer:\n",
    "\n",
    "Before training:\n",
    "- 1.1 What are the original probabilities of each image?\n",
    "- 1.2 Do male images have different probabilities than female images?\n",
    "- 1.3 Can I differentiate male/female images by their log-probabities? I can look at how the log-probs vary per step.\n",
    "- 1.4 Can I find a visual pattern when ranking images by total log-prob?\n",
    "- 1.5 What about when I rank them by log-prob in specific timesteps?\n",
    "- 1.6 How does the average log-prob vary across steps?\n",
    "- 1.7 How does the variance of the log-probs vary across steps?\n",
    "- 1.8 What is the distribution of rewards? And advantages?\n",
    "- 1.9 Are the rewards consistent with the visual aspect of the images?\n",
    "\n",
    "Training with a single sampling iteration and multiple training steps:\n",
    "\n",
    "*About log-prob*\n",
    "- 2.1 How does the log-prob vary across the epochs for each image?\n",
    "- 2.2 How does the log-prob rank vary across the epochs for each image?\n",
    "- 2.3 Did the rank by log-prob change from the original model?\n",
    "- 2.4 Can I find a visual pattern when ranking images by total final log-prob?\n",
    "- 2.5 If I rank them by difference between final and original log-prob can I see a different behavior between men and women?\n",
    "- 2.6 Can I notice a correlation beween visual aspect and magnitude of the change between final and original log-prob?\n",
    "- 2.7 Do samples with more extreme rewards (very high or very low) exhibit more significant shifts in their log-probabilities?\n",
    "\n",
    "- 2.8 How does the average log-prob vary across epochs - overall and per sex?\n",
    "- 2.9 How does the variance of the log-probs vary across epochs - overall and per sex?\n",
    "- 2.10 Can I see the distribution of men and women shifting across the epochs?\n",
    "\n",
    "- 2.11 How does the log-prob vary across the epochs for each individual step?\n",
    "- 2.12 Can I see a different behaviors at different steps?\n",
    "- 2.11 How is the difference between men and women at each step? Maybe plot men - women for each step\n",
    "- 2.12 Do I see a pattern of increasing log-probs for women and decreasing log-prob for men?\n",
    "\n",
    "\n",
    "*About the importance ratio*\n",
    "- 3.1 How does the importance ratio varies across the epochs for each?\n",
    "- 3.2 Can I tell men and women apart by looking at the above curve?\n",
    "- 3.3 How does the importance ratio vary across the epochs for each individual step?\n",
    "- 3.4 Do I see the average importance ratio for men increasing and for women decreasing?\n",
    "- 3.5 What is the distribution of importance ratios for men and women at each epoch? Do the distributions start to drift throughout the epochs?\n",
    "- 3.6 What is the variance of the importance ratio at each step?\n",
    "- 3.7 Do we see steps that don't change much from the original log-prob?\n",
    "- 3.8 The variance of the importance ratio changes over the epochs?\n",
    "\n",
    "*About clipping*\n",
    "- 4.1 What is the distribution of number of clipped ratios per step per epoch? Like, maybe plot a histogram per step, then each bin is an epoch and the height of the bin is the number of samples that had the importance ratio clipped in that step and epoch.\n",
    "- 4.2 What if I do the above plot but stack two bars: one for women and one for men?\n",
    "- 4.3 How are the statistics (mean and var) of the log-prob affected if I mask them using a \"clipped\" mask?\n",
    "- 4.4 Do I actually see the log-prob curves being smoothed when I remove values that were clipped?\n",
    "\n",
    "*About the gradients*\n",
    "- 5.1 Which steps contribute more to the gradients?\n",
    "- 5.2 How do the gradients vary across epochs? \n",
    "- 5.3 Do the gradients from men and women vary differently across steps?\n",
    "- 5.4 What is the variance of the gradients at each step? Are the gradients very different for each image?\n",
    "- 5.5 Do male images have more impact on the gradient then female images overall?\n",
    "- 5.6 What about at each step? Can I spot different gradient behavior between men and women in specific steps?\n",
    "- 5.7 How does the log prob relate to the gradient?\n",
    "- 5.8 How sensitive are the gradients to different rewards?\n",
    "- 5.9 How do changes in gradients impact the log-probs in the next epoch for each image?\n",
    "\n",
    "\n",
    "*About the final loss*\n",
    "- 6.1 How does the final loss evolve across training epochs?\n",
    "- 6.2 Is there a correlation between loss and gradient magnitude?\n",
    "- 6.3 How does the loss relate to changes in log probabilities?\n",
    "- 6.4 Does the loss decrease more for male or female samples?\n",
    "- 6.5 Is there a relationship between importance ratio and loss?\n",
    "- 6.6 If I mask the final loss by clipping, are the relationships clearer?\n",
    "- 6.7 Are there specific timesteps that contribute more to the final loss?\n",
    "- 6.8 How does the variance of the loss change throughout training?\n",
    "- 6.9 Is the loss more sensitive to changes in early or late diffusion steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideas\n",
    "- Use validation set\n",
    "- What if I only encourage the model to generate male samples without punishing it for generating female samples?\n",
    "I would love to see the log-likelihoods of the some intermediate steps of the female samples start to decrease, even without being explicitly punished.\n",
    "\n",
    "- Look into trajectory bifurcation in diffusion models. Maybe I don't need to generate N whole trajectories. Since the beginning of all the trajectories is just removing basic noise, maybe I could use the same early denoising steps for various images\n",
    "\n",
    "- I like the ideas of that paper about RL for DLLMs\n",
    "\n",
    "- I need to review the reward model. Maybe do a 2-step verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read experiment report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"reinforce_log_1_sampling_40_epochs_5_prompts_all_steps_grad.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"experiments\", EXPERIMENT_NAME))\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(batch, sample, experiment_name):\n",
    "    image_path = f\"{experiment_name}/batch{batch}_sample{sample}.png\"\n",
    "    \n",
    "    # Check if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load and display the image\n",
    "    img = plt.imread(image_path)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Batch {batch}, Sample {sample}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional columns (run with cautious depending on the experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gradient`column represents the current gradient norm. This gradient norm is accumulated across all the steps of a batch.\n",
    "\n",
    "To estimate the contribution of a given step to the overall gradient, we can do:\n",
    "\n",
    "```gradient_contribution = current_gradient_norm - previous_gradient_norm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contribution of each step to the gradient norm \n",
    "df['gradient_per_step'] = df.groupby(['epoch', 'batch'])['gradient'].transform(lambda x: x - x.shift().fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get timestep as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the step column by extracting the integer from the tensor string\n",
    "# Example: convert \"tensor(70)\" to 70\n",
    "import re\n",
    "\n",
    "def extract_number_from_tensor(tensor_str):\n",
    "    if isinstance(tensor_str, str) and 'tensor' in tensor_str:\n",
    "        # Extract the number between parentheses\n",
    "        match = re.search(r'tensor\\((\\d+)\\)', tensor_str)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    # If it's already a number or doesn't match the pattern, return as is\n",
    "    return tensor_str\n",
    "\n",
    "# Apply the function to convert the step column\n",
    "df[\"step\"] = df[\"step\"].apply(extract_number_from_tensor)\n",
    "\n",
    "# Verify the column is now numeric\n",
    "print(f\"Step column dtype after conversion: {df['step'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `sampling_epoch` has multiple `epoch`s. The new `overall_epoch` column assings a new overall index to each inner epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_epochs = df[\"epoch\"].nunique()\n",
    "df['overall_epoch'] = df['sampling_epoch'] * inner_epochs + df['epoch'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column to identify sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"reward\"].apply(lambda x: \"male\" if x>0.5 else \"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-training analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What are the original probabilities of each image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for overall_epoch=0\n",
    "epoch0_df = df[df['overall_epoch'] == 0]\n",
    "\n",
    "# Group by batch, group, sample and sum the log_prob_old\n",
    "log_probs_summed = epoch0_df.groupby(['batch', 'group', 'sample'])['log_prob_old'].sum().reset_index()\n",
    "\n",
    "# Merge with other information (sex and reward)\n",
    "samples_info = df.drop_duplicates(subset=[\"batch\", \"group\", \"sample\"])[[\"batch\", \"group\", \"sample\", \"sex\", \"reward\", \"advantage\"]]\n",
    "samples = pd.merge(samples_info, log_probs_summed, on=['batch', 'group', 'sample'])\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to load and display images for each sample\n",
    "def load_sample_images(df, experiment_name):\n",
    "    images = {}\n",
    "    for _, row in df.iterrows():\n",
    "        batch = row['batch']\n",
    "        group = row['group']\n",
    "        sample = row['sample']\n",
    "        \n",
    "        # Construct the filename\n",
    "        filename = f\"batch_{batch}_group_{group}_sample_{sample}.png\"\n",
    "        filepath = os.path.join(experiment_name, filename)\n",
    "        \n",
    "        # Try to load the image\n",
    "        try:\n",
    "            img = Image.open(filepath)\n",
    "            images[(batch, group, sample)] = img\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {filepath}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Load images for each sample\n",
    "sample_images = load_sample_images(samples, os.path.join(\"experiments\", EXPERIMENT_NAME[:-4]))\n",
    "\n",
    "# Sort samples by log_prob_old in descending order\n",
    "sorted_samples = samples.sort_values(by='log_prob_old', ascending=False)\n",
    "\n",
    "# Display images sorted by log_prob_old (descending)\n",
    "n_rows = len(sorted_samples) // 4\n",
    "fig, axes = plt.subplots(n_rows, 4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(sorted_samples.iterrows()):\n",
    "    batch = row['batch']\n",
    "    group = row['group']\n",
    "    sample = row['sample']\n",
    "    sex = row['sex']\n",
    "    log_prob = row['log_prob_old']\n",
    "    \n",
    "    # Get the image\n",
    "    img_key = (batch, group, sample)\n",
    "    if img_key in sample_images:\n",
    "        axes[i].imshow(np.array(sample_images[img_key]))\n",
    "        axes[i].set_title(f\"Batch {batch}, Group {group}, Sample {sample}\\nSex: {sex}\\nLog Prob: {log_prob:.2f}\", fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, \"Image not found\", ha='center', va='center')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Do male images have different probabilities than female images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log_prob_old distribution by sex\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='sex', y='log_prob_old', data=samples, hue='sex', palette=['skyblue', 'pink'])\n",
    "plt.title('Distribution of Log Probabilities by Sex')\n",
    "plt.ylabel('Log Probability')\n",
    "plt.xlabel('Sex')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a histogram of log probabilities colored by sex\n",
    "plt.figure(figsize=(8, 4))\n",
    "for sex_type in ['male', 'female']:\n",
    "    subset = samples[samples['sex'] == sex_type]\n",
    "    plt.hist(subset['log_prob_old'], alpha=0.5, label=sex_type, bins=15, color='skyblue' if sex_type == 'male' else 'pink')\n",
    "plt.title('Histogram of Log Probabilities by Sex')\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and variance of log_prob_old for each sex\n",
    "log_prob_stats = samples.groupby('sex')['log_prob_old'].agg(['mean', 'var', 'std', 'count'])\n",
    "print(\"Log Probability Statistics by Sex:\")\n",
    "print(log_prob_stats)\n",
    "\n",
    "# Perform t-test to check if the difference is statistically significant\n",
    "from scipy import stats\n",
    "male_log_probs = samples[samples['sex'] == 'male']['log_prob_old']\n",
    "female_log_probs = samples[samples['sex'] == 'female']['log_prob_old']\n",
    "t_stat, p_value = stats.ttest_ind(male_log_probs, female_log_probs, equal_var=False)\n",
    "\n",
    "print(\"\\nT-test for difference in log probabilities between sexes:\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.8f}\")\n",
    "print(f\"Statistically significant difference: {p_value < 0.05}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Can I differentiate male/female images by their log-probabities? I can look at how the log-probs vary per step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They did not show significant difference overall. Let's check in specific steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for overall_epoch=0\n",
    "epoch0_df = df[df['overall_epoch'] == 0]\n",
    "samples_per_step = epoch0_df[[\"step\", \"batch\", \"group\", \"sample\", \"sex\", \"reward\", \"log_prob_old\"]]\n",
    "\n",
    "\n",
    "samples_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique steps\n",
    "steps = samples_per_step['step'].unique()\n",
    "\n",
    "# Create a figure with subplots\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(steps) / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# For each step, plot the distribution of log probabilities by sex\n",
    "for i, step in enumerate(steps):\n",
    "    if i < len(axes):  # Ensure we don't go out of bounds\n",
    "        step_data = samples_per_step[samples_per_step['step'] == step]\n",
    "        \n",
    "        # Plot distributions with histogram and KDE using seaborn\n",
    "        import seaborn as sns\n",
    "        for sex_type in ['male', 'female']:\n",
    "            subset = step_data[step_data['sex'] == sex_type]\n",
    "            # Plot histogram with KDE\n",
    "            sns.histplot(subset['log_prob_old'], ax=axes[i], kde=True, \n",
    "                        color='skyblue' if sex_type == 'male' else 'pink',\n",
    "                        alpha=0.5, label=sex_type, bins=15, stat=\"density\")\n",
    "\n",
    "        \n",
    "        axes[i].set_title(f'Step {step}')\n",
    "        axes[i].set_xlabel('Log Probability')\n",
    "        axes[i].set_ylabel('Density')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Can I find a visual pattern when ranking images by total log-prob?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did it in 1.1. It doesn't seem like it :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 What about when I rank them by log-prob in specific timesteps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique samples and steps\n",
    "epoch0_df = df[df['overall_epoch'] == 0]\n",
    "unique_samples = epoch0_df[['batch', 'group', 'sample', 'sex']].drop_duplicates()\n",
    "steps = sorted(epoch0_df['step'].unique())\n",
    "\n",
    "# Create subplots - one row per sample, two columns\n",
    "n_samples = len(unique_samples)\n",
    "fig, axes = plt.subplots(n_samples, 2, figsize=(15, 4*n_samples))\n",
    "\n",
    "# Plot each sample\n",
    "for idx, (_, row) in enumerate(unique_samples.iterrows()):\n",
    "    batch, group, sample = row['batch'], row['group'], row['sample']\n",
    "    img_key = (batch, group, sample)\n",
    "    \n",
    "    # Plot image in first column\n",
    "    if img_key in sample_images:\n",
    "        axes[idx, 0].imshow(np.array(sample_images[img_key]))\n",
    "    axes[idx, 0].set_title(f\"Sample {sample} ({row['sex']})\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Plot rankings in second column\n",
    "    rankings = []\n",
    "    for step in steps:\n",
    "        step_data = epoch0_df[epoch0_df['step'] == step]\n",
    "        # First sort, then reset index to get proper ranking\n",
    "        sorted_data = step_data.sort_values('log_prob_old', ascending=False).reset_index(drop=True)\n",
    "        rank = sorted_data.index[\n",
    "            (sorted_data['batch'] == batch) & \n",
    "            (sorted_data['group'] == group) & \n",
    "            (sorted_data['sample'] == sample)\n",
    "        ].values[0]\n",
    "        rankings.append(rank)\n",
    "    \n",
    "    axes[idx, 1].plot(steps, rankings, 'o-', color = 'skyblue' if row[\"sex\"] == \"male\" else \"pink\")\n",
    "    axes[idx, 1].set_title(f'Ranking across steps')\n",
    "    axes[idx, 1].set_xlabel('Step')\n",
    "    axes[idx, 1].set_ylabel('Rank')\n",
    "    axes[idx, 1].grid(True)\n",
    "    axes[idx, 1].invert_yaxis()  # Make rank 0 at the top\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Calculate and plot average rankings for each sex\n",
    "for sex in ['male', 'female']:\n",
    "    avg_rankings = []\n",
    "    std_rankings = []  # for error bars\n",
    "    \n",
    "    for step in steps:\n",
    "        step_data = epoch0_df[epoch0_df['step'] == step]\n",
    "        sorted_data = step_data.sort_values('log_prob_old', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        # Get rankings for all samples of this sex\n",
    "        sex_ranks = sorted_data.index[sorted_data['sex'] == sex].values\n",
    "        \n",
    "        # Calculate average and std of rankings\n",
    "        avg_rankings.append(np.mean(sex_ranks))\n",
    "        std_rankings.append(np.std(sex_ranks))\n",
    "    \n",
    "    # Plot average ranking with error bars\n",
    "    plt.plot(steps, avg_rankings, \n",
    "                label=sex.capitalize(), \n",
    "                marker='o',\n",
    "                color='pink' if sex == 'female' else 'skyblue')\n",
    "\n",
    "plt.title('Average Ranking by Sex Across Steps')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Average Rank')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()  # Make rank 0 at the top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_data = []\n",
    "step_labels = []\n",
    "sex_labels = []\n",
    "\n",
    "for step in steps:\n",
    "    step_data = epoch0_df[epoch0_df['step'] == step]\n",
    "    sorted_data = step_data.sort_values('log_prob_old', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    for sex in ['male', 'female']:\n",
    "        sex_ranks = sorted_data.index[sorted_data['sex'] == sex].values\n",
    "        ranks_data.extend(sex_ranks)\n",
    "        step_labels.extend([step] * len(sex_ranks))\n",
    "        sex_labels.extend([sex] * len(sex_ranks))\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Step': step_labels,\n",
    "    'Sex': sex_labels,\n",
    "    'Rank': ranks_data\n",
    "})\n",
    "\n",
    "# Box plot\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.boxplot(data=plot_df, x='Step', y='Rank', hue='Sex', \n",
    "            palette={'male': 'skyblue', 'female': 'pink'})\n",
    "plt.title('Distribution of Ranks by Sex and Step (Box Plot)')\n",
    "plt.gca().invert_yaxis()  # Use plt.gca().invert_yaxis() instead of plt.invert_yaxis()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 How does the average log-prob vary across steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average log probability per step\n",
    "avg_log_prob_per_step = df.groupby('step')['log_prob_old'].mean().reset_index()\n",
    "\n",
    "# Plot the average log probability across steps\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(avg_log_prob_per_step['step'], avg_log_prob_per_step['log_prob_old'], marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Log Probability Across Steps', fontsize=14)\n",
    "plt.xlabel('Step', fontsize=12)\n",
    "plt.ylabel('Average Log Probability', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(avg_log_prob_per_step['step'][::max(1, len(avg_log_prob_per_step)//10)])  # Show fewer x-ticks for clarity\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 How does the variance of the log-probs vary across steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance of log probability per step\n",
    "var_log_prob_per_step = df.groupby('step')['log_prob_old'].var().reset_index()\n",
    "\n",
    "# Plot the variance of log probability across steps\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(var_log_prob_per_step['step'], var_log_prob_per_step['log_prob_old'], \n",
    "         marker='o', linestyle='-', color='blue', alpha=0.7, label='Raw Data')\n",
    "\n",
    "# Add smoothed curve using moving average\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "smoothed = gaussian_filter1d(var_log_prob_per_step['log_prob_old'], sigma=2)\n",
    "plt.plot(var_log_prob_per_step['step'], smoothed, \n",
    "         linestyle='--', color='red', linewidth=0.5, label='Smoothed Trend')\n",
    "\n",
    "plt.title('Variance of Log Probability Across Steps', fontsize=14)\n",
    "plt.xlabel('Step', fontsize=12)\n",
    "plt.ylabel('Variance of Log Probability', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(var_log_prob_per_step['step'][::max(1, len(var_log_prob_per_step)//10)])  # Show fewer x-ticks for clarity\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 What is the distribution of rewards? And advantages? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reward distribution by sex\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Male rewards histogram\n",
    "male_rewards = samples[samples['sex'] == 'male']['reward']\n",
    "ax1.hist(male_rewards, bins=100, alpha=0.7, \n",
    "         color='skyblue', edgecolor='black', label='Male')\n",
    "ax1.set_title('Male Reward Distribution', fontsize=14)\n",
    "ax1.set_xlabel('Reward Value', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Female rewards histogram\n",
    "female_rewards = samples[samples['sex'] == 'female']['reward']\n",
    "ax2.hist(female_rewards, bins=100, alpha=0.7, \n",
    "         color='pink', edgecolor='black', label='Female')\n",
    "ax2.set_title('Female Reward Distribution', fontsize=14)\n",
    "ax2.set_xlabel('Reward Value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze advantage distribution by sex\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Male advantages histogram\n",
    "male_advantages = samples[samples['sex'] == 'male']['advantage']\n",
    "ax1.hist(male_advantages, bins=100, alpha=0.7,\n",
    "         color='skyblue', edgecolor='black', label='Male')\n",
    "ax1.set_title('Male Advantage Distribution', fontsize=14)\n",
    "ax1.set_xlabel('Advantage Value', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Female advantages histogram\n",
    "female_advantages = samples[samples['sex'] == 'female']['advantage']\n",
    "ax2.hist(female_advantages, bins=100, alpha=0.7,\n",
    "         color='pink', edgecolor='black', label='Female')\n",
    "ax2.set_title('Female Advantage Distribution', fontsize=14)\n",
    "ax2.set_xlabel('Advantage Value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Are the rewards consistent with the visual aspect of the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to load and display images for each sample\n",
    "def load_sample_images(df, experiment_name):\n",
    "    images = {}\n",
    "    for _, row in df.iterrows():\n",
    "        batch = row['batch']\n",
    "        group = row['group']\n",
    "        sample = row['sample']\n",
    "        \n",
    "        # Construct the filename\n",
    "        filename = f\"batch_{batch}_group_{group}_sample_{sample}.png\"\n",
    "        filepath = os.path.join(experiment_name, filename)\n",
    "        \n",
    "        # Try to load the image\n",
    "        try:\n",
    "            img = Image.open(filepath)\n",
    "            images[(batch, group, sample)] = img\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {filepath}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Load images for each sample\n",
    "sample_images = load_sample_images(samples, os.path.join(\"experiments\", EXPERIMENT_NAME[:-4]))\n",
    "\n",
    "# Sort samples by log_prob_old in descending order\n",
    "sorted_samples = samples.sort_values(by='reward', ascending=False)\n",
    "\n",
    "# Display images sorted by log_prob_old (descending)\n",
    "n_rows = len(sorted_samples) // 4\n",
    "fig, axes = plt.subplots(n_rows, 4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(sorted_samples.iterrows()):\n",
    "    batch = row['batch']\n",
    "    group = row['group']\n",
    "    sample = row['sample']\n",
    "    sex = row['sex']\n",
    "    reward = row['reward']\n",
    "    \n",
    "    # Get the image\n",
    "    img_key = (batch, group, sample)\n",
    "    if img_key in sample_images:\n",
    "        axes[i].imshow(np.array(sample_images[img_key]))\n",
    "        axes[i].set_title(f\"Batch {batch}, Group {group}, Sample {sample}\\nSex: {sex}\\nReward: {reward:.4f}\", fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, \"Image not found\", ha='center', va='center')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysing log-prob throughout the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 How does the log-prob vary across the epochs for each image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by batch, group, sample and sum the log_prob_new\n",
    "log_probs_summed = df.groupby(['overall_epoch', 'batch', 'group', 'sample'])['log_prob_new'].sum().reset_index()\n",
    "\n",
    "# Merge with other information (sex and reward)\n",
    "samples_info = df.drop_duplicates(subset=[\"overall_epoch\", \"batch\", \"group\", \"sample\"])[[\"overall_epoch\", \"batch\", \"group\", \"sample\", \"sex\"]]\n",
    "samples = pd.merge(samples_info, log_probs_summed, on=['overall_epoch', 'batch', 'group', 'sample'])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique sample identifiers\n",
    "unique_samples = samples.drop_duplicates(['batch', 'group', 'sample'])[['batch', 'group', 'sample']]\n",
    "sample_ids = list(zip(unique_samples['batch'], unique_samples['group'], unique_samples['sample']))\n",
    "\n",
    "# Create a single figure with subplots for each sample\n",
    "num_samples = len(sample_ids)\n",
    "rows = int(np.ceil(num_samples / 4))  # 4 columns\n",
    "fig, axes = plt.subplots(rows, 4, figsize=(20, 5*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Group samples by batch, group, and sample to track each image across epochs\n",
    "grouped_samples = samples.groupby(['batch', 'group', 'sample'])\n",
    "\n",
    "for i, (batch, group, sample) in enumerate(sample_ids):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get the data for this sample\n",
    "        sample_data = grouped_samples.get_group((batch, group, sample))\n",
    "        \n",
    "        # Get the sex from the first row (should be consistent for all epochs of same sample)\n",
    "        sex = sample_data['sex'].iloc[0]\n",
    "        \n",
    "        # Get the final log probability for display in title\n",
    "        final_log_prob = sample_data[sample_data['overall_epoch'] == sample_data['overall_epoch'].max()]['log_prob_new'].values[0]\n",
    "        \n",
    "        ax.plot(sample_data[\"overall_epoch\"], sample_data['log_prob_new'], marker='o', \n",
    "                color='skyblue' if sex == 'male' else 'pink', \n",
    "                label=f'Sex: {sex}')\n",
    "        ax.set_title(f'Batch {batch}, Group {group}, Sample {sample}\\nFinal log_prob: {final_log_prob:.2f}')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Log Probability (New)')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle('Evolution of Log Probability over Epochs', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot showing log_prob for men and women across epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filter data for males and females\n",
    "male_data = samples[samples['sex'] == 'male']\n",
    "female_data = samples[samples['sex'] == 'female']\n",
    "\n",
    "# Create handles for the legend\n",
    "male_patch = plt.scatter([], [], color='skyblue', alpha=0.5, label='Male')\n",
    "female_patch = plt.scatter([], [], color='pink', alpha=0.5, label='Female')\n",
    "\n",
    "# Plot males\n",
    "for (batch, group, sample), group_data in samples[samples['sex'] == 'male'].groupby(['batch', 'group', 'sample']):\n",
    "    plt.scatter(group_data['overall_epoch'], group_data['log_prob_new'], color='skyblue', alpha=0.5)\n",
    "    \n",
    "# Plot females\n",
    "for (batch, group, sample), group_data in samples[samples['sex'] == 'female'].groupby(['batch', 'group', 'sample']):\n",
    "    plt.scatter(group_data['overall_epoch'], group_data['log_prob_new'], color='pink', alpha=0.5)\n",
    "\n",
    "plt.title('Log Probability Across Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log Probability')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(handles=[male_patch, female_patch], loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 How does the log-prob rank vary across the epochs for each image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_samples = samples[['batch', 'group', 'sample', 'sex']].drop_duplicates()\n",
    "epochs = sorted(samples['overall_epoch'].unique())\n",
    "\n",
    "# Create subplots - one row per sample, two columns\n",
    "n_samples = len(unique_samples)\n",
    "fig, axes = plt.subplots(n_samples, 2, figsize=(15, 4*n_samples))\n",
    "\n",
    "# Plot each sample\n",
    "for idx, (_, row) in enumerate(unique_samples.iterrows()):\n",
    "    batch, group, sample = row['batch'], row['group'], row['sample']\n",
    "    img_key = (batch, group, sample)\n",
    "    \n",
    "    # Plot image in first column\n",
    "    if img_key in sample_images:\n",
    "        axes[idx, 0].imshow(np.array(sample_images[img_key]))\n",
    "    axes[idx, 0].set_title(f\"Sample {sample} ({row['sex']})\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Plot rankings in second column\n",
    "    rankings = []\n",
    "    for epoch in epochs:\n",
    "        epoch_data = samples[samples['overall_epoch'] == epoch]\n",
    "        # First sort, then reset index to get proper ranking\n",
    "        sorted_data = epoch_data.sort_values('log_prob_new', ascending=False).reset_index(drop=True)\n",
    "        rank = sorted_data.index[\n",
    "            (sorted_data['batch'] == batch) & \n",
    "            (sorted_data['group'] == group) & \n",
    "            (sorted_data['sample'] == sample)\n",
    "        ].values[0]\n",
    "        rankings.append(rank)\n",
    "    \n",
    "    axes[idx, 1].plot(epochs, rankings, 'o-', color = 'skyblue' if row[\"sex\"] == \"male\" else \"pink\")\n",
    "    axes[idx, 1].set_title(f'Ranking across steps')\n",
    "    axes[idx, 1].set_xlabel('Step')\n",
    "    axes[idx, 1].set_ylabel('Rank')\n",
    "    axes[idx, 1].grid(True)\n",
    "    axes[idx, 1].invert_yaxis()  # Make rank 0 at the top\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot showing rank by log_prob for men and women across epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filter data for males and females\n",
    "male_data = samples[samples['sex'] == 'male']\n",
    "female_data = samples[samples['sex'] == 'female']\n",
    "\n",
    "# For each epoch, calculate the rank for each sample\n",
    "all_ranks = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    epoch_data = samples[samples['overall_epoch'] == epoch]\n",
    "    # Sort by log_prob_new in descending order and reset index to get ranks\n",
    "    sorted_data = epoch_data.sort_values('log_prob_new', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Add rank information to the sorted data\n",
    "    sorted_data['rank'] = sorted_data.index\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    rank_data = sorted_data[['overall_epoch', 'batch', 'group', 'sample', 'sex', 'rank']]\n",
    "    all_ranks.append(rank_data)\n",
    "\n",
    "# Combine all rank data\n",
    "rank_df = pd.concat(all_ranks)\n",
    "\n",
    "# Create handles for the legend\n",
    "male_patch = plt.scatter([], [], color='skyblue', alpha=0.5, label='Male')\n",
    "female_patch = plt.scatter([], [], color='pink', alpha=0.5, label='Female')\n",
    "\n",
    "# Plot males\n",
    "for (batch, group, sample), group_data in rank_df[rank_df['sex'] == 'male'].groupby(['batch', 'group', 'sample']):\n",
    "    plt.scatter(group_data['overall_epoch'], group_data['rank'], color='skyblue', alpha=0.5)\n",
    "    \n",
    "# Plot females\n",
    "for (batch, group, sample), group_data in rank_df[rank_df['sex'] == 'female'].groupby(['batch', 'group', 'sample']):\n",
    "    plt.scatter(group_data['overall_epoch'], group_data['rank'], color='pink', alpha=0.5)\n",
    "\n",
    "plt.title('Rank by Log Probability Across Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Rank (lower is better)')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis so rank 0 is at the top\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(handles=[male_patch, female_patch], loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3 Did the rank by log-prob change from the original model?\n",
    "- 2.4 Can I find a visual pattern when ranking images by total final log-prob?\n",
    "- 2.5 If I rank them by difference between final and original log-prob can I see a different behavior between men and women?\n",
    "- 2.6 Can I notice a correlation beween visual aspect and magnitude of the change between final and original log-prob?\n",
    "- 2.7 Do samples with more extreme rewards (very high or very low) exhibit more significant shifts in their log-probabilities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Did the rank by log-prob change from the original model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by batch, group, sample and sum the log_prob_new\n",
    "log_probs_summed = df.groupby(['overall_epoch', 'batch', 'group', 'sample'])[['log_prob_old', 'log_prob_new']].sum().reset_index()\n",
    "\n",
    "# Merge with other information (sex and reward)\n",
    "samples_info = df.drop_duplicates(subset=[\"overall_epoch\", \"batch\", \"group\", \"sample\"])[[\"overall_epoch\", \"batch\", \"group\", \"sample\", \"sex\"]]\n",
    "samples = pd.merge(samples_info, log_probs_summed, on=['overall_epoch', 'batch', 'group', 'sample'])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images for each sample\n",
    "sample_images = load_sample_images(samples, os.path.join(\"experiments\", EXPERIMENT_NAME[:-4]))\n",
    "\n",
    "# Get the last epoch data\n",
    "last_epoch = samples['overall_epoch'].max()\n",
    "last_epoch_samples = samples[samples['overall_epoch'] == last_epoch]\n",
    "\n",
    "# Sort samples by log_prob_old and log_prob_new in descending order\n",
    "sorted_by_old = last_epoch_samples.sort_values(by='log_prob_old', ascending=False)\n",
    "sorted_by_new = last_epoch_samples.sort_values(by='log_prob_new', ascending=False)\n",
    "\n",
    "# Create a figure with two columns\n",
    "n_samples = len(sorted_by_old)\n",
    "fig, axes = plt.subplots(n_samples, 2, figsize=(8, n_samples * 1.5))\n",
    "\n",
    "# Left column: sorted by log_prob_old\n",
    "for i, (_, row) in enumerate(sorted_by_old.iterrows()):\n",
    "    batch, group, sample = row['batch'], row['group'], row['sample']\n",
    "    sex, log_prob = row['sex'], row['log_prob_old']\n",
    "    \n",
    "    img_key = (batch, group, sample)\n",
    "    if img_key in sample_images:\n",
    "        axes[i, 0].imshow(np.array(sample_images[img_key]))\n",
    "        axes[i, 0].set_title(f\"Log-prob: {log_prob:.4f}\", fontsize=8)\n",
    "    else:\n",
    "        axes[i, 0].text(0.5, 0.5, \"No image\", ha='center', va='center', fontsize=6)\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "# Right column: sorted by log_prob_new\n",
    "for i, (_, row) in enumerate(sorted_by_new.iterrows()):\n",
    "    batch, group, sample = row['batch'], row['group'], row['sample']\n",
    "    sex, log_prob = row['sex'], row['log_prob_new']\n",
    "    \n",
    "    img_key = (batch, group, sample)\n",
    "    if img_key in sample_images:\n",
    "        axes[i, 1].imshow(np.array(sample_images[img_key]))\n",
    "        axes[i, 1].set_title(f\"Log-prob: {log_prob:.4f}\", fontsize=8)\n",
    "    else:\n",
    "        axes[i, 1].text(0.5, 0.5, \"No image\", ha='center', va='center', fontsize=6)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "# Add column titles\n",
    "fig.text(0.3, 0.98, \"Ranked by Original Log Prob\", ha='center', fontsize=8, fontweight='bold')\n",
    "fig.text(0.7, 0.98, \"Ranked by Final Log Prob\", ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.96)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 How are the original log-probs correlated with the final log-probs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of log_prob_old vs log_prob_new for the last epoch\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create scatter plot with a proper legend\n",
    "male_samples = last_epoch_samples[last_epoch_samples['sex'] == 'male']\n",
    "female_samples = last_epoch_samples[last_epoch_samples['sex'] == 'female']\n",
    "\n",
    "plt.scatter(male_samples['log_prob_old'], male_samples['log_prob_new'], \n",
    "            alpha=0.9, color='skyblue', label='Male', s=50)\n",
    "plt.scatter(female_samples['log_prob_old'], female_samples['log_prob_new'], \n",
    "            alpha=0.9, color='pink', label='Female', s=50)\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "min_val = min(last_epoch_samples['log_prob_old'].min(), last_epoch_samples['log_prob_new'].min())\n",
    "max_val = max(last_epoch_samples['log_prob_old'].max(), last_epoch_samples['log_prob_new'].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='Diagonal reference', linewidth=1)\n",
    "\n",
    "# Calculate Pearson and Spearman correlations\n",
    "pearson_corr = last_epoch_samples['log_prob_old'].corr(last_epoch_samples['log_prob_new'], method='pearson')\n",
    "spearman_corr = last_epoch_samples['log_prob_old'].corr(last_epoch_samples['log_prob_new'], method='spearman')\n",
    "\n",
    "# Add correlation information to the plot\n",
    "plt.annotate(f'Pearson correlation: {pearson_corr:.4f}\\nSpearman correlation: {spearman_corr:.4f}',\n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Original Log Probability (log_prob_old)')\n",
    "plt.ylabel('Final Log Probability (log_prob_new)')\n",
    "plt.title('Correlation between Original and Final Log Probabilities')\n",
    "\n",
    "# Add a legend with correct order\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Can I see a different behaviors at different steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Do I loose too much information by agregating the above analysis by sex? If the curves from the same sex are similar, I probably don't\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 How is the difference between men and women at each step? Maybe plot men - women for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Do I see a pattern of increasing log-probs for women and decreasing log-prob for men?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Answer the questions from the \"Before training\" section but now with the final log-probs after training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Did the rank by log-prob change from the original model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_cols = len(df.columns)\n",
    "num_rows = (num_cols + 2) // 3\n",
    "fig, axs = plt.subplots(num_rows, 3, figsize=(15, 5*num_rows))\n",
    "for i, column in enumerate(df.columns):\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column].value_counts().plot(kind='bar', ax=axs[i//3, i%3], title=column, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axs[i//3, i%3].set_xlabel('Value')\n",
    "        axs[i//3, i%3].set_ylabel('Frequency')\n",
    "        axs[i//3, i%3].grid(True)\n",
    "    else:\n",
    "        df[column].plot(kind='hist', ax=axs[i//3, i%3], title=column, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axs[i//3, i%3].set_xlabel('Value')\n",
    "        axs[i//3, i%3].set_ylabel('Frequency')\n",
    "        axs[i//3, i%3].grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do probabilities behave across steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the steps to display\n",
    "steps = sorted(df[\"step\"].unique())[::6]\n",
    "num_steps = len(steps)\n",
    "\n",
    "# Create a grid layout with appropriate dimensions\n",
    "rows = (num_steps + 3) // 4  # 4 plots per row\n",
    "cols = min(4, num_steps)\n",
    "\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "axs = axs.flatten() if num_steps > 1 else [axs]\n",
    "\n",
    "for i, step in enumerate(steps):\n",
    "    step_data = df[df[\"step\"] == step]\n",
    "    \n",
    "    # Split data by sex\n",
    "    female_data = step_data[step_data[\"sex\"] == \"female\"][\"log_prob_new\"]\n",
    "    male_data = step_data[step_data[\"sex\"] == \"male\"][\"log_prob_new\"]\n",
    "    \n",
    "    # Create boxplot with one box per sex\n",
    "    box_data = [female_data, male_data]\n",
    "    box_colors = ['pink', 'lightblue']\n",
    "    \n",
    "    bp = axs[i].boxplot(box_data, patch_artist=True, tick_labels=['female', 'male'])\n",
    "    \n",
    "    # Color the boxes\n",
    "    for patch, color in zip(bp['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axs[i].set_title(f'Step {step}\\nVariance: {step_data[\"log_prob_new\"].var():.4f}')\n",
    "    axs[i].set_ylabel('Log Prob New')\n",
    "    axs[i].grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(num_steps, len(axs)):\n",
    "    axs[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Get the variance data\n",
    "step_variance = df.groupby(['step'])[\"log_prob_new\"].var()\n",
    "\n",
    "# Plot the original data points\n",
    "plt.plot(step_variance, marker='o', linestyle='-', color='b', alpha=0.5, label='Original')\n",
    "\n",
    "# Apply smoothing using a moving average\n",
    "window_size = 5\n",
    "smoothed_variance = step_variance.rolling(window=window_size, center=True).mean()\n",
    "\n",
    "# Plot the smoothed curve\n",
    "plt.plot(smoothed_variance, linewidth=1, color='r', label='Smoothed (Moving Avg)', linestyle=\"--\")\n",
    "\n",
    "plt.title('Variance of log_prob_new per step (with smoothed tendency)')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last step in the dataset\n",
    "last_step = df['step'].min()\n",
    "\n",
    "# Filter data for the last step and epoch 0\n",
    "last_step_data = df[(df['step'] == last_step) & (df['epoch'] == 0)]\n",
    "\n",
    "# Sort by log_prob_new in descending order\n",
    "sorted_data = last_step_data.sort_values(by='log_prob_new', ascending=False)\n",
    "\n",
    "sorted_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data[\"log_prob_new\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is higher between steps 30 and 40.\n",
    "\n",
    "Just as a reminder: the log-prob refers to p(xt-1|xt)\n",
    "\n",
    "A low variance of log-prob means that all the images have approximately the same likelihood of happening in that step.\n",
    "\n",
    "A high variance of log-prob means that different images have considerably different likelihood of happening in that step.\n",
    "\n",
    ">if i sample multiple trajectories and compute the log-prob of each image at each step, what should i expect from a curve of step vs variance of log-prob?\n",
    "\n",
    "That's a great question about the statistical properties of log-probabilities across different sampling trajectories!\n",
    "\n",
    "If you sample multiple trajectories and compute the log-probability at each timestep, the variance of these log-probabilities across trajectories would show a distinctive pattern:\n",
    "\n",
    "1. **At t=T (start of sampling)**: \n",
    "   - Low variance between trajectories\n",
    "   - Log-probabilities would be similar since all trajectories start from roughly the same pure noise distribution\n",
    "\n",
    "2. **Middle timesteps (T/2)**:\n",
    "   - Highest variance between trajectories\n",
    "   - Different trajectories are exploring different modes of the distribution\n",
    "   - The sampling process is in a phase where trajectories are maximally divergent\n",
    "\n",
    "3. **Final timesteps (approaching t=0)**:\n",
    "   - Decreasing variance\n",
    "   - As trajectories converge toward their final images\n",
    "   - The model's predictions become more certain\n",
    "\n",
    "4. **At t=0**:\n",
    "   - If included with a small epsilon: Extremely low variance between trajectories\n",
    "   - The final denoising step is almost deterministic\n",
    "   - Log-probabilities would be very similar (and very large) across all samples\n",
    "\n",
    "So the expected curve of step vs. variance of log-prob would roughly follow an inverted U-shape: starting low, rising to a peak in the middle timesteps, then decreasing again toward the end.\n",
    "\n",
    "This pattern emerges because:\n",
    "- Early timesteps: All trajectories are operating on similar noise patterns\n",
    "- Middle timesteps: Trajectories differentiate as they explore the probability space\n",
    "- Late timesteps: Trajectories become more deterministic as they approach their final states\n",
    "\n",
    "This variance analysis can actually provide insights into where your diffusion model is making its most critical decisions during the generation process!\n",
    "\n",
    "> humm... interesting. this is what i'm seeing, but here's somehting i dont understand: the distributions p(xt-1|xt) have decreasing variance. so in the first timestpes, the variance would be large. but why when i sample various xt-1 from these early timesteps they have such similar likelihood?\n",
    "\n",
    "That's a really insightful observation that gets at a key property of diffusion models!\n",
    "\n",
    "You're right that there seems to be a paradox:\n",
    "- The distributions p(x_{t-1}|x_t) have higher variance at early timesteps (t close to T)\n",
    "- Yet when you sample different x_{t-1} from these distributions, they have similar log-likelihoods\n",
    "\n",
    "This happens because of the relationship between distribution spread and information content:\n",
    "\n",
    "1. **High noise levels (early timesteps):**\n",
    "   - The distributions p(x_{t-1}|x_t) have high variance\n",
    "   - BUT they're also very broad/flat distributions centered around similar means\n",
    "   - In a broad Gaussian, points that are quite far apart can still have similar probability densities\n",
    "   - The log-likelihood surface is relatively \"flat\" with gradual slopes\n",
    "\n",
    "2. **Middle timesteps:**\n",
    "   - The distributions become more structured and multimodal\n",
    "   - Different trajectories start exploring genuinely different semantic regions\n",
    "   - The log-likelihood surface develops \"peaks\" and \"valleys\"\n",
    "   - Points from different trajectories are now in regions with very different likelihood values\n",
    "\n",
    "3. **Low noise levels (late timesteps):**\n",
    "   - The distributions have low variance but are highly structured\n",
    "   - Small differences in position produce large differences in likelihood\n",
    "   - However, the trajectories have largely converged to their final destinations\n",
    "\n",
    "Think of it like this: In early timesteps, you're sampling from \"almost pure noise\" distributions where almost any sample is about as likely as any other. The distributions are wide but uniform-like in their central regions. As you progress through timesteps, the distributions become more structured and \"opinionated\" about which samples are high quality.\n",
    "\n",
    "This is why your variance of log-probabilities follows an inverted U-shape even though the variance of the actual distributions p(x_{t-1}|x_t) decreases monotonically through the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.groupby(['step'])[\"log_prob_new\"].mean(), marker='o', linestyle='-', color='b')\n",
    "plt.title('Mean of log_prob_new per step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Mean')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log probabilities increase across timesteps (as t decreases) because:\n",
    "\n",
    "1. The variance of p(x_{t-1}|x_t) gets smaller as we approach t=0\n",
    "2. Smaller variance means higher precision (1/variance)\n",
    "3. Higher precision leads to more concentrated probability density\n",
    "4. More concentrated density = higher peak probability values\n",
    "5. The log of these higher probability values results in larger log probabilities\n",
    "\n",
    "This is fundamentally because we're going from diffuse, high-entropy distributions (at large t) to concentrated, low-entropy distributions (at small t), which naturally have higher maximum probability densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define steps to analyze (every n steps)\n",
    "steps_to_analyze = sorted(df[\"step\"].unique())[::6]\n",
    "n_steps = len(steps_to_analyze)\n",
    "\n",
    "# Create a figure with 2 columns (mean and variance) and rows for each step\n",
    "fig, axs = plt.subplots(n_steps, 2, figsize=(12, 4*n_steps))\n",
    "\n",
    "for i, step in enumerate(steps_to_analyze):\n",
    "    step_by_epoch = df[df[\"step\"]==step].groupby(\"overall_epoch\")\n",
    "    \n",
    "    # Plot mean\n",
    "    axs[i, 0].plot(step_by_epoch[\"log_prob_new\"].mean(), marker='o', linestyle='-', color='b')\n",
    "    axs[i, 0].set_title(f'Mean of log_prob_new per epoch in step {step}')\n",
    "    axs[i, 0].set_ylabel('Mean')\n",
    "    \n",
    "    # Show fewer x-ticks to avoid crowding\n",
    "    min_epoch = min(step_by_epoch.groups.keys())\n",
    "    max_epoch = max(step_by_epoch.groups.keys())\n",
    "    tick_interval = max(1, (max_epoch - min_epoch) // 5)  # Show at most ~5 ticks\n",
    "    axs[i, 0].set_xticks(range(min_epoch, max_epoch + 1, tick_interval))\n",
    "    \n",
    "    # Plot variance\n",
    "    axs[i, 1].plot(step_by_epoch[\"log_prob_new\"].var(), marker='o', linestyle='-', color='b')\n",
    "    axs[i, 1].set_title(f'Variance of log_prob_new per epoch in step {step}')\n",
    "    axs[i, 1].set_ylabel('Variance')\n",
    "    \n",
    "    # Use the same tick interval for the second plot\n",
    "    axs[i, 1].set_xticks(range(min_epoch, max_epoch + 1, tick_interval))\n",
    "    \n",
    "    # Add grid and labels\n",
    "    for ax in axs[i]:\n",
    "        ax.grid(True)\n",
    "        ax.set_xlabel('Epoch')  # Add x-label for clarity\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the contribution of each step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the male and female likelihoods different from each other in the original model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sample_prob = df.groupby(['overall_epoch', 'batch', 'group', 'sample']).sum()\n",
    "per_sample_prob.reset_index(inplace=True)\n",
    "\n",
    "# Filter for a specific epoch (using 0 as an example)\n",
    "epoch_data = per_sample_prob[per_sample_prob[\"overall_epoch\"]==0]\n",
    "\n",
    "# Define colors based on gender\n",
    "colors = ['pink' if \"female\" in sex else 'blue' for sex in epoch_data[\"sex\"]]\n",
    "\n",
    "# Create bar plot with adjusted y-axis to better show differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Sort data to better visualize patterns\n",
    "sorted_indices = epoch_data['log_prob_old'].argsort()\n",
    "sorted_data = epoch_data.iloc[sorted_indices]\n",
    "sorted_colors = [colors[i] for i in sorted_indices]\n",
    "\n",
    "# Calculate min and max for better y-axis limits\n",
    "min_val = sorted_data['log_prob_old'].min()\n",
    "max_val = sorted_data['log_prob_old'].max()\n",
    "y_margin = (max_val - min_val) * 0.1  # 10% margin\n",
    "\n",
    "plt.bar(range(len(sorted_data)), \n",
    "        sorted_data['log_prob_old'], \n",
    "        color=sorted_colors,\n",
    "        alpha=0.7,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5)\n",
    "\n",
    "# Set y-axis limits to zoom in on the differences\n",
    "plt.ylim(min_val - y_margin, max_val + y_margin)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of log_prob_old Across Samples')\n",
    "plt.xlabel('Sample Index (sorted by log_prob_old)')\n",
    "plt.ylabel('Log Prob Old')\n",
    "\n",
    "# Add legend for gender colors\n",
    "import matplotlib.patches as mpatches\n",
    "pink_patch = mpatches.Patch(color='pink', label='Female')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Male')\n",
    "plt.legend(handles=[pink_patch, blue_patch])\n",
    "\n",
    "# Show plot with more prominent grid for easier comparison\n",
    "plt.grid(True, alpha=0.5, axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems messy. Maybe I can check if the probabilities are better differentiated in specific steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define step interval for plotting\n",
    "step_interval = 3  # Plot every 5 steps\n",
    "\n",
    "# Get unique steps in the data\n",
    "unique_steps = sorted(df[\"step\"].unique())\n",
    "\n",
    "# Select steps at regular intervals\n",
    "steps_to_plot = unique_steps[::step_interval]\n",
    "\n",
    "# Calculate number of rows and columns for the grid\n",
    "n_plots = len(steps_to_plot)\n",
    "n_cols = 4  # Number of columns in the grid (changed from 2 to 4)\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols  # Ceiling division to get number of rows\n",
    "\n",
    "# Create a figure with a grid of subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 2.5 * n_rows))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easier indexing\n",
    "\n",
    "# Create plots for each selected step\n",
    "for i, step in enumerate(steps_to_plot):\n",
    "    # Filter data for the current step and epoch 0\n",
    "    step_data = df[(df[\"step\"] == step) & (df[\"overall_epoch\"] == 0)]\n",
    "    \n",
    "    # Group by sample to get per-sample data at this specific step\n",
    "    # Convert object columns to appropriate types before aggregation\n",
    "    numeric_cols = ['log_prob_old', 'log_prob_new']\n",
    "    per_sample_step = step_data.groupby(['batch', 'group', 'sample']).agg(\n",
    "        {col: 'mean' for col in numeric_cols}\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Merge back non-numeric columns we need (like sex)\n",
    "    # Get one row per sample to avoid duplicates\n",
    "    sample_info = step_data.groupby(['batch', 'group', 'sample']).first()[['sex']].reset_index()\n",
    "    per_sample_step = pd.merge(per_sample_step, sample_info, on=['batch', 'group', 'sample'])\n",
    "    \n",
    "    # Define colors based on gender\n",
    "    colors = ['pink' if \"female\" in sex else 'blue' for sex in per_sample_step[\"sex\"]]\n",
    "    \n",
    "    # Get the current axis\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Sort data to better visualize patterns\n",
    "    sorted_indices = per_sample_step['log_prob_old'].argsort()\n",
    "    sorted_data = per_sample_step.iloc[sorted_indices]\n",
    "    sorted_colors = [colors[i] for i in sorted_indices]\n",
    "    \n",
    "    # Calculate min and max for better y-axis limits\n",
    "    min_val = sorted_data['log_prob_old'].min()\n",
    "    max_val = sorted_data['log_prob_old'].max()\n",
    "    y_margin = (max_val - min_val) * 0.1  # 10% margin\n",
    "    \n",
    "    ax.bar(range(len(sorted_data)), \n",
    "           sorted_data['log_prob_old'], \n",
    "           color=sorted_colors,\n",
    "           alpha=0.7,\n",
    "           edgecolor='black',\n",
    "           linewidth=0.5)\n",
    "    \n",
    "    # Set y-axis limits to zoom in on the differences\n",
    "    ax.set_ylim(min_val - y_margin, max_val + y_margin)\n",
    "    \n",
    "    # Add titles and labels with smaller font size\n",
    "    ax.set_title(f'Step {step}', fontsize=9)\n",
    "    ax.set_xlabel('Sample Index', fontsize=8)\n",
    "    ax.set_ylabel('Log Prob Old', fontsize=8)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "    \n",
    "    # Add grid for easier comparison\n",
    "    ax.grid(True, alpha=0.5, axis='y', linestyle='--')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "# Add a common legend for the entire figure\n",
    "import matplotlib.patches as mpatches\n",
    "pink_patch = mpatches.Patch(color='pink', label='Female')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Male')\n",
    "fig.legend(handles=[pink_patch, blue_patch], loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=2)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Make room for the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... Maybe they weren't supposed to be separate. In the end, they are sampled from the same distribution, it's reasonable to think that all images have high likelihoods, otherwise they wouldn't be sampled.\n",
    "\n",
    "I could only explore this if I somehow managed to get trajectories without actually sampling. Then I would probably see that, overall, women samples have higher likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Get unique steps in the data\n",
    "unique_steps = sorted(df[\"step\"].unique())\n",
    "\n",
    "# Select steps at regular intervals\n",
    "steps_to_plot = unique_steps[::step_interval]\n",
    "\n",
    "for step in steps_to_plot:\n",
    "    step_data = df[df[\"step\"] == step]\n",
    "    \n",
    "    # Calculate averages for male and female\n",
    "    female_data = step_data[step_data[\"sex\"].str.contains(\"female\")]\n",
    "    male_data = step_data[~step_data[\"sex\"].str.contains(\"female\")]\n",
    "    \n",
    "    # Create figure with three subplots side by side\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 3))\n",
    "    \n",
    "    \n",
    "    # First subplot - Scatter plot with all data\n",
    "    ax1.scatter(female_data[\"overall_epoch\"], \n",
    "               female_data[\"log_prob_new\"], \n",
    "               c='pink', \n",
    "               s=50, \n",
    "               alpha=0.7, \n",
    "               edgecolors='w', \n",
    "               linewidth=0.5,\n",
    "               label='Female')\n",
    "    \n",
    "    ax1.scatter(male_data[\"overall_epoch\"], \n",
    "               male_data[\"log_prob_new\"], \n",
    "               c='blue', \n",
    "               s=50, \n",
    "               alpha=0.7, \n",
    "               edgecolors='w', \n",
    "               linewidth=0.5,\n",
    "               label='Male')\n",
    "    \n",
    "    # Add titles and labels\n",
    "    ax1.set_title(f'Log Prob New vs. Epochs (Step {step})')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Log Prob New')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Second subplot - Female averages only\n",
    "    if not female_data.empty:\n",
    "        # Group by epoch and calculate mean\n",
    "        female_avg = female_data.groupby(\"overall_epoch\")[\"log_prob_new\"].mean()\n",
    "        ax2.plot(female_avg.index, female_avg.values, 'pink', linestyle='-', linewidth=2, label='Female Avg')\n",
    "\n",
    "        # Find peaks\n",
    "        peaks, _ = find_peaks(female_avg.values, distance=1)  # Adjust distance as needed\n",
    "        peak_x = [female_avg.index[i] for i in peaks]\n",
    "        peak_y = [female_avg.values[i] for i in peaks]\n",
    "        ax2.plot(peak_x, peak_y, c='black', linewidth=0.8, linestyle='--', marker='o', markersize=2, alpha=0.7, label='Peaks')\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax2.set_title(f'Female Average Log Prob New (Step {step})')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Average Log Prob New')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Third subplot - Male averages only\n",
    "    if not male_data.empty:\n",
    "        # Group by epoch and calculate mean\n",
    "        male_avg = male_data.groupby(\"overall_epoch\")[\"log_prob_new\"].mean()\n",
    "        ax3.plot(male_avg.index, male_avg.values, 'blue', linestyle='-', linewidth=2, label='Male Avg')\n",
    "    \n",
    "        minima, _ = find_peaks(male_avg.values, distance=1)  # Adjust distance as needed\n",
    "        min_x = [male_avg.index[i] for i in minima]\n",
    "        min_y = [male_avg.values[i] for i in minima]\n",
    "        ax3.plot(min_x, min_y, c='black', linewidth=0.8, linestyle='--', marker='o', markersize=3, alpha=0.7, label='Minima')\n",
    "\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax3.set_title(f'Male Average Log Prob New (Step {step})')\n",
    "    ax3.set_xlabel('Epochs')\n",
    "    ax3.set_ylabel('Average Log Prob New')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some conclusions:\n",
    "1. It's not obvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"batch\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the original probabilities for each sampling epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Get unique sampling epochs\n",
    "sampling_epochs = df[\"sampling_epoch\"].unique()\n",
    "\n",
    "# Get steps to keep\n",
    "steps = sorted(df[\"step\"].unique())  \n",
    "steps_to_keep = steps[20:40] \n",
    "\n",
    "# Create one plot per sampling epoch\n",
    "for sampling_epoch in sampling_epochs:\n",
    "    # Filter data for the current sampling epoch\n",
    "    df_sampling = df[(df[\"sampling_epoch\"] == sampling_epoch)]\n",
    "    \n",
    "    # Group by step and gender to calculate averages\n",
    "    # Convert to numeric first to avoid TypeError with object dtype\n",
    "    female_df = df_sampling[df_sampling[\"sex\"] == \"female\"].copy()\n",
    "    male_df = df_sampling[df_sampling[\"sex\"] == \"male\"].copy()\n",
    "    \n",
    "    # Ensure log_prob_old is numeric\n",
    "    female_df[\"log_prob_new\"] = pd.to_numeric(female_df[\"log_prob_new\"], errors='coerce')\n",
    "    male_df[\"log_prob_new\"] = pd.to_numeric(male_df[\"log_prob_new\"], errors='coerce')\n",
    "    \n",
    "    # Now calculate means\n",
    "    female_avg = female_df.groupby(\"step\")[\"log_prob_new\"].mean()\n",
    "    male_avg = male_df.groupby(\"step\")[\"log_prob_new\"].mean()\n",
    "    \n",
    "    # Filter the averages to include only the selected steps\n",
    "    female_avg_filtered = female_avg.loc[female_avg.index.intersection(steps_to_keep)]\n",
    "    male_avg_filtered = male_avg.loc[male_avg.index.intersection(steps_to_keep)]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if not female_avg_filtered.empty:                \n",
    "        plt.plot(female_avg_filtered.index, female_avg_filtered.values, 'pink', linestyle='-', linewidth=2, label='Female Avg')\n",
    "\n",
    "    if not male_avg_filtered.empty:\n",
    "        plt.plot(male_avg_filtered.index, male_avg_filtered.values, 'blue', linestyle='-', linewidth=2, label='Male Avg')\n",
    "    \n",
    "    # Add titles and labels\n",
    "    plt.title(f'Average Log Prob Old vs. Step (Sampling Epoch {sampling_epoch}, Steps 20-40)')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Average Log Prob Old')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the summed loss_clip for each sample\n",
    "sample_loss_sums = df.groupby(['sampling_epoch', 'batch', 'group', 'sample'])['loss_clip'].sum().reset_index()\n",
    "\n",
    "# Create a bar plot for the summed loss_clip for each sample\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['pink' if loss < 0 else 'blue' for loss in sample_loss_sums['loss_clip']]\n",
    "plt.bar(range(len(sample_loss_sums)), sample_loss_sums['loss_clip'], color=colors)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Summed Loss Clip for Each Sample')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Summed Loss Clip')\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "# Add a horizontal line at y=0 for reference\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "avg_pink_old = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['log_prob_old'].mean()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "avg_blue_old = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['log_prob_old'].mean()\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].plot(avg_pink.index, avg_pink_old.values, linestyle='--', label='Reference model', color='pink')\n",
    "axs[0].set_title('Average Log Prob New over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Log Prob New')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].plot(avg_pink.index, avg_blue_old.values, linestyle='--', label='Reference model', color='blue')\n",
    "axs[1].set_title('Average Log Prob New over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Log Prob New')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average Log Prob New over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Log Prob New')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a line plot for each sample within each sampling epoch, epoch, and batch showing the evolution of loss_clip over computed epochs\n",
    "grouped = per_sample_stats.groupby(['sampling_epoch', 'batch', 'group', 'sample'])\n",
    "for (sampling_epoch, batch, group, sample), sample_data in grouped:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    color = 'pink' if sample_data['loss_clip'].iloc[0] < 0 else 'blue'\n",
    "    plt.plot(sample_data[\"epoch\"], sample_data['loss_clip'], marker='o', color=color, label=f'Sampling epoch {sampling_epoch}, Batch {batch}, Group {group}, Sample {sample}')\n",
    "    plt.title(f'Evolution of Loss Clip over Computed Epochs')\n",
    "    plt.xlabel('Computed Epochs')\n",
    "    plt.ylabel('Loss Clip')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot for each sample showing the evolution of importance_ratio over steps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_samples = len(df.groupby(['sampling_epoch', 'batch', 'group', 'sample']))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each group and corresponding subplot\n",
    "for ax, ((sampling_epoch, batch, group, sample), sample_data) in zip(axes, df.groupby(['sampling_epoch', 'batch', 'group', 'sample'])):\n",
    "    gender = 'Man' if sample_data['loss_clip'].sum() > 0 else 'Woman'\n",
    "    for epoch, epoch_data in sample_data.groupby('epoch'):\n",
    "        ax.plot(epoch_data['step'], epoch_data['importance_ratio'], marker='o', label=f'Epoch {epoch}')\n",
    "    ax.axhline(y=1-1e-4, color='gray', linestyle='--', linewidth=1, label='Lower Clip (1-1e-4)')\n",
    "    ax.axhline(y=1+1e-4, color='gray', linestyle='--', linewidth=1, label='Upper Clip (1+1e-4)')\n",
    "    ax.set_title(f'Sample {sample} / Batch {batch} ({gender})')\n",
    "    ax.set_xlabel('Steps')\n",
    "    ax.set_ylabel('Importance Ratio')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[num_samples:]:\n",
    "    ax.set_visible(False)\n",
    "plt.suptitle('Evolution of Importance Ratio over Timesteps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_prob_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to see the gradient aggregated by sex over the epochs. but the gradient is saved to df accumulated. also it would be interesting to see percentage of clipping. like, for a given epoch, what percentage of the steps\n",
    "# why the last step has that high probabilty which is the same for all images?\n",
    "# aggregate gradient (without accumulation) by step,sex, one line per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot for each sample showing the evolution of log_prob_new over steps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_samples = len(df.groupby(['sampling_epoch', 'batch', 'group', 'sample']))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each group and corresponding subplot\n",
    "for ax, ((sampling_epoch, batch, group, sample), sample_data) in zip(axes, df.groupby(['sampling_epoch', 'batch', 'group', 'sample'])):\n",
    "    gender = 'Man' if sample_data['loss_clip'].sum() > 0 else 'Woman'\n",
    "    for epoch, epoch_data in sample_data.groupby('epoch'):\n",
    "        ax.plot(epoch_data['step'][:-4], epoch_data['log_prob_new'][:-4], marker='o', label=f'Epoch {epoch}')\n",
    "    ax.axhline(y=1-1e-4, color='gray', linestyle='--', linewidth=1, label='Lower Clip (1-1e-4)')\n",
    "    ax.axhline(y=1+1e-4, color='gray', linestyle='--', linewidth=1, label='Upper Clip (1+1e-4)')\n",
    "    ax.set_title(f'Sample {sample} / Batch {batch} ({gender})')\n",
    "    ax.set_xlabel('Steps')\n",
    "    ax.set_ylabel('Log Probability New')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[num_samples:]:\n",
    "    ax.set_visible(False)\n",
    "plt.suptitle('Evolution of Log Probability New over Timesteps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot for each sample showing the evolution of gradient over steps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_samples = len(df.groupby(['sampling_epoch', 'batch', 'group', 'sample']))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each group and corresponding subplot\n",
    "for ax, ((sampling_epoch, batch, group, sample), sample_data) in zip(axes, df.groupby(['sampling_epoch', 'batch', 'group', 'sample'])):\n",
    "    gender = 'Man' if sample_data['loss_clip'].sum() > 0 else 'Woman'\n",
    "    for epoch, epoch_data in sample_data.groupby('epoch'):\n",
    "        ax.plot(epoch_data['step'], epoch_data['gradient_per_step'], marker='o', label=f'Epoch {epoch}')\n",
    "    ax.axhline(y=1-1e-4, color='gray', linestyle='--', linewidth=1, label='Lower Clip (1-1e-4)')\n",
    "    ax.axhline(y=1+1e-4, color='gray', linestyle='--', linewidth=1, label='Upper Clip (1+1e-4)')\n",
    "    ax.set_title(f'Sample {sample} / Batch {batch} ({gender})')\n",
    "    ax.set_xlabel('Steps')\n",
    "    ax.set_ylabel('Gradient')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[num_samples:]:\n",
    "    ax.set_visible(False)\n",
    "plt.suptitle('Evolution of Gradient over Timesteps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot for each sample showing the evolution of importance_ratio over steps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_samples = len(df.groupby(['sampling_epoch', 'batch', 'group', 'sample']))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(30, 10), sharex=True)\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each group and corresponding subplot\n",
    "for ax, ((sampling_epoch, batch, group, sample), sample_data) in zip(axes, df.groupby(['sampling_epoch', 'batch', 'group', 'sample'])):\n",
    "    gender = 'Man' if sample_data['loss_clip'].sum() > 0 else 'Woman'\n",
    "    for epoch, epoch_data in sample_data.groupby('epoch'):\n",
    "        ax.plot(epoch_data['step'], epoch_data['loss_clip'], marker='o', label=f'Epoch {epoch}')\n",
    "    ax.set_title(f'Sample {sample} / Batch {batch} ({gender})')\n",
    "    ax.set_xlabel('Steps')\n",
    "    ax.set_ylabel('Loss clip')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[num_samples:]:\n",
    "    ax.set_visible(False)\n",
    "plt.suptitle('Evolution of Loss clip over Timesteps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a line plot for each sample within each sampling epoch, epoch, and batch showing the evolution of log_prob_new over computed epochs\n",
    "grouped = per_sample_stats.groupby(['sampling_epoch', 'batch', 'group', 'sample'])\n",
    "for (sampling_epoch, batch, group, sample), sample_data in grouped:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    color = 'pink' if sample_data['loss_clip'].iloc[0] < 0 else 'blue'\n",
    "    plt.plot(sample_data[\"epoch\"], sample_data['kl_loss'], marker='o', color=color, label=f'Sampling epoch {sampling_epoch}, Batch {batch}, Group {group}, Sample {sample}')\n",
    "    plt.title(f'Evolution of KL loss over Computed Epochs')\n",
    "    plt.xlabel('Computed Epochs')\n",
    "    plt.ylabel('KL loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average KL loss of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink_kl = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['kl_loss'].mean()\n",
    "avg_blue_kl = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['kl_loss'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink_kl.index, avg_pink_kl.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average KL Loss over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average KL Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue_kl.index, avg_blue_kl.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average KL Loss over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average KL Loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink_kl.index, avg_pink_kl.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue_kl.index, avg_blue_kl.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average KL Loss over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average KL Loss')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average gradient per step of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink_grad = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['gradient_per_step'].mean()\n",
    "avg_blue_grad = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['gradient_per_step'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink_grad.index, avg_pink_grad.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average Gradient per Step over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Gradient per Step')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue_grad.index, avg_blue_grad.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average Gradient per Step over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Gradient per Step')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink_grad.index, avg_pink_grad.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue_grad.index, avg_blue_grad.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average Gradient per Step over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Gradient per Step')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average KL loss of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink_kl = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['kl_loss'].mean()\n",
    "avg_blue_kl = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['kl_loss'].mean()\n",
    "\n",
    "avg_pink_loss_base = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['loss_base'].mean()\n",
    "avg_blue_loss_base = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['loss_base'].mean()\n",
    "\n",
    "# Normalize the data\n",
    "avg_pink_kl = (avg_pink_kl - avg_pink_kl.mean()) / avg_pink_kl.std()\n",
    "avg_blue_kl = (avg_blue_kl - avg_blue_kl.mean()) / avg_blue_kl.std()\n",
    "avg_pink_loss_base = (avg_pink_loss_base - avg_pink_loss_base.mean()) / avg_pink_loss_base.std()\n",
    "avg_blue_loss_base = (avg_blue_loss_base - avg_blue_loss_base.mean()) / avg_blue_loss_base.std()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink_kl.index, avg_pink_kl.values, marker='o', color='pink', label='KL Loss (Women)')\n",
    "axs[0].plot(avg_pink_loss_base.index, avg_pink_loss_base.values, marker='x', linestyle='--', color='pink', label='Loss Base (Women)')\n",
    "axs[0].set_title('Average KL Loss over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average KL Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue_kl.index, avg_blue_kl.values, marker='o', color='blue', label='KL Loss (Men)')\n",
    "axs[1].plot(avg_blue_loss_base.index, avg_blue_loss_base.values, marker='x', linestyle='--', color='blue', label='Loss Base (Men)')\n",
    "axs[1].set_title('Average KL Loss over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average KL Loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink_kl.index, avg_pink_kl.values, marker='o', color='pink', label='KL Loss (Women)')\n",
    "axs[2].plot(avg_blue_kl.index, avg_blue_kl.values, marker='o', color='blue', label='KL Loss (Men)')\n",
    "axs[2].plot(avg_pink_loss_base.index, avg_pink_loss_base.values, marker='x', linestyle='--', color='pink', label='Loss Base (Women)')\n",
    "axs[2].plot(avg_blue_loss_base.index, avg_blue_loss_base.values, marker='x', linestyle='--', color='blue', label='Loss Base (Men)')\n",
    "axs[2].set_title('Average KL Loss over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average KL Loss')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average importance ratio of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink_importance_ratio = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['importance_ratio'].mean()\n",
    "avg_blue_importance_ratio = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['importance_ratio'].mean()\n",
    "\n",
    "avg_pink_clipped_ratio = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "avg_blue_clipped_ratio = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "\n",
    "# Define min and max lines\n",
    "min_line = 50 * (1 - 1e-4)\n",
    "max_line = 50 * (1 + 1e-4)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(22, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink_importance_ratio.index, avg_pink_importance_ratio.values, marker='o', color='pink', label='Importance Ratio (Women)')\n",
    "axs[0].plot(avg_pink_clipped_ratio.index, avg_pink_clipped_ratio.values, marker='x', linestyle='--', color='pink', label='Clipped Ratio (Women)')\n",
    "axs[0].axhline(y=min_line, color='grey', linestyle='--', label='Min Line')\n",
    "axs[0].axhline(y=max_line, color='grey', linestyle='--', label='Max Line')\n",
    "axs[0].set_title('Average Importance Ratio over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Importance Ratio')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue_importance_ratio.index, avg_blue_importance_ratio.values, marker='o', color='blue', label='Importance Ratio (Men)')\n",
    "axs[1].plot(avg_blue_clipped_ratio.index, avg_blue_clipped_ratio.values, marker='x', linestyle='--', color='blue', label='Clipped Ratio (Men)')\n",
    "axs[1].axhline(y=min_line, color='grey', linestyle='--', label='Min Line')\n",
    "axs[1].axhline(y=max_line, color='grey', linestyle='--', label='Max Line')\n",
    "axs[1].set_title('Average Importance Ratio over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Importance Ratio')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink_importance_ratio.index, avg_pink_importance_ratio.values, marker='o', color='pink', label='Importance Ratio (Women)')\n",
    "axs[2].plot(avg_blue_importance_ratio.index, avg_blue_importance_ratio.values, marker='o', color='blue', label='Importance Ratio (Men)')\n",
    "axs[2].plot(avg_pink_clipped_ratio.index, avg_pink_clipped_ratio.values, marker='x', linestyle='--', color='pink', label='Clipped Ratio (Women)')\n",
    "axs[2].plot(avg_blue_clipped_ratio.index, avg_blue_clipped_ratio.values, marker='x', linestyle='--', color='blue', label='Clipped Ratio (Men)')\n",
    "axs[2].axhline(y=min_line, color='grey', linestyle='--', label='Min Line')\n",
    "axs[2].axhline(y=max_line, color='grey', linestyle='--', label='Max Line')\n",
    "axs[2].set_title('Average Importance Ratio over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Importance Ratio')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "avg_overall = per_sample_stats.groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 10))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0, 0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0, 0].set_title('Average Clipped Ratio over Computed Epochs (Women Samples)')\n",
    "axs[0, 0].set_xlabel('Computed Epochs')\n",
    "axs[0, 0].set_ylabel('Average Clipped Ratio')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[0, 1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[0, 1].set_title('Average Clipped Ratio over Computed Epochs (Men Samples)')\n",
    "axs[0, 1].set_xlabel('Computed Epochs')\n",
    "axs[0, 1].set_ylabel('Average Clipped Ratio')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[1, 0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[1, 0].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[1, 0].set_title('Average Clipped Ratio over Computed Epochs (Women and Men Samples)')\n",
    "axs[1, 0].set_xlabel('Computed Epochs')\n",
    "axs[1, 0].set_ylabel('Average Clipped Ratio')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "# Plot for overall average\n",
    "axs[1, 1].plot(avg_overall.index, avg_overall.values, marker='o', color='green', label='Overall Average')\n",
    "axs[1, 1].set_title('Overall Average Clipped Ratio over Computed Epochs')\n",
    "axs[1, 1].set_xlabel('Computed Epochs')\n",
    "axs[1, 1].set_ylabel('Overall Average Clipped Ratio')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "avg_overall = per_sample_stats.groupby('computed_epoch')['clipped_ratio'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 10))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0, 0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0, 0].set_title('Average Clipped Ratio over Computed Epochs (Women Samples)')\n",
    "axs[0, 0].set_xlabel('Computed Epochs')\n",
    "axs[0, 0].set_ylabel('Average Clipped Ratio')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[0, 1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[0, 1].set_title('Average Clipped Ratio over Computed Epochs (Men Samples)')\n",
    "axs[0, 1].set_xlabel('Computed Epochs')\n",
    "axs[0, 1].set_ylabel('Average Clipped Ratio')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[1, 0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[1, 0].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[1, 0].set_title('Average Clipped Ratio over Computed Epochs (Women and Men Samples)')\n",
    "axs[1, 0].set_xlabel('Computed Epochs')\n",
    "axs[1, 0].set_ylabel('Average Clipped Ratio')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "# Plot for overall average\n",
    "axs[1, 1].plot(avg_overall.index, avg_overall.values, marker='o', color='green', label='Overall Average')\n",
    "axs[1, 1].set_title('Overall Average Clipped Ratio over Computed Epochs')\n",
    "axs[1, 1].set_xlabel('Computed Epochs')\n",
    "axs[1, 1].set_ylabel('Overall Average Clipped Ratio')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['loss_base'].sum()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['loss_base'].sum()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average Loss Base over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Loss Base')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average Loss Base over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Loss Base')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Normalize the values so that they can be seen in the same scale\n",
    "avg_pink_norm = (avg_pink - avg_pink.min()) / (avg_pink.max() - avg_pink.min())\n",
    "avg_blue_norm = (avg_blue - avg_blue.min()) / (avg_blue.max() - avg_blue.min())\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink_norm.index, avg_pink_norm.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue_norm.index, avg_blue_norm.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average Loss Base over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Loss Base (Normalized)')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['gradient_per_step'].sum()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['gradient_per_step'].sum()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average Gradient over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Gradient')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average Gradient over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Gradient')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].plot(avg_blue.index, avg_pink.values+avg_blue.values, marker='o', color='green', label='All Samples')\n",
    "axs[2].set_title('Average Gradient over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Gradient')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average Log Prob New over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Log Prob New')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average Log Prob New over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Log Prob New')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average Log Prob New over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Log Prob New')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "avg_pink = per_sample_stats[per_sample_stats['loss_clip'] < 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "avg_blue = per_sample_stats[per_sample_stats['loss_clip'] >= 0].groupby('computed_epoch')['log_prob_new'].mean()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Training model')\n",
    "axs[0].set_title('Average Log Prob New over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Average Log Prob New')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Training model')\n",
    "axs[1].set_title('Average Log Prob New over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Average Log Prob New')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(avg_pink.index, avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "axs[2].plot(avg_blue.index, avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "axs[2].set_title('Average Log Prob New over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Average Log Prob New')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "per_sample_stats['computed_epoch'] = per_sample_stats['sampling_epoch'] * 3 + per_sample_stats['epoch'] + per_sample_stats['sampling_epoch']\n",
    "\n",
    "# Normalize probabilities and log probabilities to range from 0 to 1 for women and men separately\n",
    "women_samples = per_sample_stats[per_sample_stats['loss_clip'] < 0]\n",
    "men_samples = per_sample_stats[per_sample_stats['loss_clip'] >= 0]\n",
    "\n",
    "\n",
    "# Group by computed_epoch and find the sum of log_prob_new and gradient_per_step\n",
    "sum_pink_gradient = women_samples.groupby('computed_epoch')['gradient_per_step'].sum()\n",
    "sum_pink_prob = women_samples.groupby('computed_epoch')['log_prob_new'].sum()\n",
    "sum_blue_gradient = men_samples.groupby('computed_epoch')['gradient_per_step'].sum()\n",
    "sum_blue_prob = men_samples.groupby('computed_epoch')['log_prob_new'].sum()\n",
    "\n",
    "# Normalize the sums between 0 and 1\n",
    "sum_pink_gradient_normalized = (sum_pink_gradient - sum_pink_gradient.min()) / (sum_pink_gradient.max() - sum_pink_gradient.min())\n",
    "sum_pink_prob_normalized = (sum_pink_prob - sum_pink_prob.min()) / (sum_pink_prob.max() - sum_pink_prob.min())\n",
    "sum_blue_gradient_normalized = (sum_blue_gradient - sum_blue_gradient.min()) / (sum_blue_gradient.max() - sum_blue_gradient.min())\n",
    "sum_blue_prob_normalized = (sum_blue_prob - sum_blue_prob.min()) / (sum_blue_prob.max() - sum_blue_prob.min())\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot for pink samples\n",
    "axs[0].plot(sum_pink_gradient_normalized.index, sum_pink_gradient_normalized.values, marker='o', color='pink', label='Max of Gradient for Women Samples', markersize=4)  # Reduced marker size\n",
    "axs[0].plot(sum_pink_prob_normalized.index, sum_pink_prob_normalized.values, marker='o', color='pink', linestyle='--', label='Max of Log Prob for Women Samples', markersize=4)  # Reduced marker size\n",
    "axs[0].set_title('Max of Gradient and Log Prob over Computed Epochs (Women Samples)')\n",
    "axs[0].set_xlabel('Computed Epochs')\n",
    "axs[0].set_ylabel('Max Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for blue samples\n",
    "axs[1].plot(sum_blue_gradient_normalized.index, sum_blue_gradient_normalized.values, marker='o', color='blue', label='Max of Gradient for Men Samples', markersize=4)  # Reduced marker size\n",
    "axs[1].plot(sum_blue_prob_normalized.index, sum_blue_prob_normalized.values, marker='o', color='blue', linestyle='--', label='Max of Log Prob for Men Samples', markersize=4)  # Reduced marker size\n",
    "axs[1].set_title('Max of Gradient and Log Prob over Computed Epochs (Men Samples)')\n",
    "axs[1].set_xlabel('Computed Epochs')\n",
    "axs[1].set_ylabel('Max Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot both pink and blue samples together\n",
    "axs[2].plot(sum_pink_gradient_normalized.index, sum_pink_gradient_normalized.values, marker='o', color='pink', label='Max of Gradient for Women Samples', markersize=4)  # Reduced marker size\n",
    "axs[2].plot(sum_blue_gradient_normalized.index, sum_blue_gradient_normalized.values, marker='o', color='blue', label='Max of Gradient for Men Samples', markersize=4)  # Reduced marker size\n",
    "axs[2].plot(sum_pink_gradient_normalized.index, sum_pink_gradient_normalized.values + sum_blue_gradient_normalized.values, marker='o', color='green', label='Total Max of Gradient', markersize=4)  # Reduced marker size\n",
    "axs[2].set_title('Max of Gradient over Computed Epochs (Women and Men Samples)')\n",
    "axs[2].set_xlabel('Computed Epochs')\n",
    "axs[2].set_ylabel('Max of Gradient')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"epoch\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.04-1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average of the samples in pink and blue considering the computed epochs\n",
    "df['computed_epoch'] = df['sampling_epoch'] * 3 + df['epoch'] + df['sampling_epoch']\n",
    "\n",
    "# Compute number of epochs\n",
    "n_epochs = len(pd.unique(df[\"computed_epoch\"]))\n",
    "\n",
    "# Create subplots for each epoch\n",
    "fig, axs = plt.subplots(n_epochs, 1, figsize=(18, 40))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    avg_pink = df[(df['loss_clip'] < 0) & (df['epoch'] == epoch)].groupby(['computed_epoch', 'step'])['gradient_per_step'].mean()\n",
    "    avg_blue = df[(df['loss_clip'] >= 0) & (df['epoch'] == epoch)].groupby(['computed_epoch', 'step'])['gradient_per_step'].mean()\n",
    "    avg_total = df[df['epoch'] == epoch].groupby(['computed_epoch', 'step'])['gradient_per_step'].mean()\n",
    "\n",
    "    # Plot for pink samples\n",
    "    axs[epoch].plot(avg_pink.index.get_level_values('step'), avg_pink.values, marker='o', color='pink', label='Average of Women Samples')\n",
    "\n",
    "    # Plot for blue samples\n",
    "    axs[epoch].plot(avg_blue.index.get_level_values('step'), avg_blue.values, marker='o', color='blue', label='Average of Men Samples')\n",
    "\n",
    "    # Plot total average\n",
    "    axs[epoch].plot(avg_total.index.get_level_values('step'), avg_total.values, marker='o', color='green', label='Total Average')\n",
    "\n",
    "    axs[epoch].set_title(f'Average Gradient over Computed Epochs (Epoch {epoch})')\n",
    "    axs[epoch].set_xlabel('Step')\n",
    "    axs[epoch].set_ylabel('Average Gradient')\n",
    "    axs[epoch].legend()\n",
    "    axs[epoch].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"loss_base\"] + df[\"loss_clip\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kl_loss\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"batch\"]==0)&(df[\"sample\"]==2)].groupby(\"epoch\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[(df[\"batch\"]==0)&(df[\"sample\"]==2)&(df[\"epoch\"].isin(range(0, 8)))]\n",
    "\n",
    "# Create a figure with four subplots side by side\n",
    "fig, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "for i, epoch in enumerate(range(0, 8)):\n",
    "    importance_ratio = test[test[\"epoch\"] == epoch][\"importance_ratio\"]\n",
    "    clipped_ratio = test[test[\"epoch\"] == epoch][\"clipped_ratio\"]\n",
    "    sum_importance_ratio = importance_ratio.sum()\n",
    "    sum_clipped_ratio = clipped_ratio.sum()\n",
    "\n",
    "    ax = axs[i // 4, i % 4]\n",
    "    ax.plot(test[test[\"epoch\"] == epoch][\"step\"], importance_ratio, label='Importance Ratio', marker='o')\n",
    "    ax.plot(test[test[\"epoch\"] == epoch][\"step\"], clipped_ratio, label='Clipped Ratio', marker='x')\n",
    "    ax.set_title(f'Epoch {epoch}')\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Ratio')\n",
    "    ax.legend(title=f'Sum Importance: {sum_importance_ratio:.5f}, Sum Clipped: {sum_clipped_ratio:.5f}')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = 'man.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Generate Gaussian noise\n",
    "mean = 0\n",
    "stddev = 250  # Standard deviation of the noise\n",
    "gaussian_noise = np.random.normal(mean, stddev, image_array.shape)\n",
    "\n",
    "# Add the Gaussian noise to the image\n",
    "noisy_image_array = image_array + gaussian_noise\n",
    "\n",
    "# Clip the values to be in the valid range [0, 255]\n",
    "noisy_image_array = np.clip(noisy_image_array, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Convert back to an image\n",
    "noisy_image = Image.fromarray(noisy_image_array)\n",
    "\n",
    "# Save the noisy image\n",
    "noisy_image.save('woman_noise.jpeg')\n",
    "\n",
    "# Display the original and noisy images\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Noisy Image')\n",
    "plt.imshow(noisy_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
