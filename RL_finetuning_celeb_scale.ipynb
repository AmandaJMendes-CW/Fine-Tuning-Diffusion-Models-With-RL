{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc5rnl6WtR_b"
      },
      "source": [
        "# Load diffuser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7AO7ez3n9Znb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S2E_cub_VVI",
        "outputId": "1fb5cc6c-bfc0-4c22-b4a3-727d4728487a"
      },
      "outputs": [],
      "source": [
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "\n",
        "scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-celebahq-256\", use_safetensors = True)\n",
        "pretrained_model = UNet2DModel.from_pretrained(\"google/ddpm-celebahq-256\")\n",
        "\n",
        "# By disabling the clipping, the mean of the distribution used by the scheduler will match exactly the predicted_mean\n",
        "scheduler.config[\"clip_sample\"] = False\n",
        "scheduler = DDPMScheduler.from_config(scheduler.config)\n",
        "\n",
        "pretrained_model = pretrained_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAHvdlMRtPiH"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6fz4B-Mp_GY9"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "def display_sample(sample, label = \"\"):\n",
        "  image_processed = sample.cpu().permute(0, 2, 3, 1)\n",
        "  image_processed = (image_processed + 1.0) * 127.5\n",
        "  image_processed = image_processed.numpy().astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image_processed[0])\n",
        "  display(label)\n",
        "  display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zox6jZlttI34"
      },
      "source": [
        "# Diffusion trajectory classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H9ohAqPl9JUw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.distributions import Normal\n",
        "from typing import List, Dict, Iterator, Tuple, Optional, Callable\n",
        "from diffusers import DDPMScheduler\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DiffusionStep:\n",
        "    \"\"\"Represents a single step in the diffusion trajectory.\n",
        "\n",
        "    Attributes:\n",
        "        timestep: The timestep index in the diffusion process\n",
        "        current_sample: The noisy latent at this timestep (Xt)\n",
        "        prev_sample: The previous sample in the trajectory (Xt-1)\n",
        "        pred_noise: The predicted noise at this timestep (from original model)\n",
        "        log_prob: The log probability of this step (from original model)\n",
        "    \"\"\"\n",
        "    timestep: int\n",
        "    current_sample: Tensor\n",
        "    prev_sample: Tensor\n",
        "    pred_noise: Tensor\n",
        "    log_prob: Tensor\n",
        "    mean: Tensor\n",
        "    variance: Tensor\n",
        "\n",
        "    def compute_log_prob(self, model, scheduler) -> Tensor:\n",
        "        \"\"\"Compute log probability using a different model with the same trajectory data.\n",
        "\n",
        "        Args:\n",
        "            model: The updated diffusion model\n",
        "            scheduler: The noise scheduler\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Updated log probability for this step\n",
        "        \"\"\"\n",
        "        # Get device\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "        # Get model prediction for the noise\n",
        "        current_sample = self.current_sample.detach()\n",
        "        prev_sample = self.prev_sample.detach()\n",
        "\n",
        "        residual = model(current_sample, self.timestep).sample\n",
        "\n",
        "        # Get the distribution parameters for p(Xt-1 | Xt)\n",
        "        t = self.timestep\n",
        "        alpha_t = scheduler.alphas[t].to(device)\n",
        "        alpha_t_bar = scheduler.alphas_cumprod[t].to(device)\n",
        "        beta_t = scheduler.betas[t].to(device)\n",
        "\n",
        "        # Previous timestep's alpha_cumprod (ensuring it exists)\n",
        "        prev_t = max(0, t-1) if isinstance(t, int) else torch.maximum(torch.zeros_like(t), t-1)\n",
        "        alpha_t_prev_bar = scheduler.alphas_cumprod[prev_t].to(device)\n",
        "\n",
        "        # Calculate predicted mean and variance\n",
        "        predicted_mean = (1.0 / torch.sqrt(alpha_t)) * (\n",
        "            current_sample - (beta_t / torch.sqrt(1.0 - alpha_t_bar)) * residual\n",
        "        )\n",
        "        variance = beta_t * (1 - alpha_t_prev_bar) / (1 - alpha_t_bar)\n",
        "\n",
        "        # Create normal distribution and compute log probability\n",
        "        dist = Normal(predicted_mean, torch.sqrt(variance))\n",
        "        log_prob = dist.log_prob(prev_sample)\n",
        "\n",
        "        # Sum over all dimensions except batch\n",
        "        log_prob = log_prob.mean(dim=list(range(1, len(log_prob.shape))))\n",
        "\n",
        "        return log_prob, predicted_mean, variance\n",
        "\n",
        "\n",
        "class Trajectory:\n",
        "    \"\"\"Represents a full diffusion trajectory from noise to image.\n",
        "\n",
        "    This class allows iteration over diffusion steps and supports re-computation\n",
        "    of log probabilities with updated models without re-sampling the trajectory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        scheduler: DDPMScheduler,\n",
        "        device: torch.device,\n",
        "        num_inference_steps: Optional[int] = None,\n",
        "        starting_noise: Optional[Tensor] = None\n",
        "    ):\n",
        "        \"\"\"Initialize and generate a diffusion trajectory.\n",
        "\n",
        "        Args:\n",
        "            model: The diffusion model used to generate the trajectory\n",
        "            scheduler: The noise scheduler\n",
        "            device: The device to use for computation\n",
        "            num_inference_steps: Optional number of inference steps\n",
        "            starting_noise: Optional pre-defined noise to start from\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "\n",
        "        # Use provided number of timesteps or default to scheduler\n",
        "        self.num_inference_steps = num_inference_steps or scheduler.config.num_train_timesteps // 50\n",
        "\n",
        "        # Generate or use provided starting noise\n",
        "        if starting_noise is None:\n",
        "            latent_shape = (1, model.config.in_channels, model.config.sample_size, model.config.sample_size)\n",
        "            self.starting_noise = torch.randn(latent_shape, device=device)\n",
        "        else:\n",
        "            self.starting_noise = starting_noise.to(device)\n",
        "\n",
        "        # Generate the trajectory\n",
        "        self.steps = self._generate_trajectory()\n",
        "\n",
        "    def _generate_trajectory(self) -> List[DiffusionStep]:\n",
        "        \"\"\"Generate the complete diffusion trajectory.\n",
        "\n",
        "        Returns:\n",
        "            List[DiffusionStep]: A list of diffusion steps from noise to image\n",
        "        \"\"\"\n",
        "        steps = []\n",
        "\n",
        "        # Initialize the scheduler and start with pure noise\n",
        "        self.scheduler.set_timesteps(self.num_inference_steps)\n",
        "        latent = self.starting_noise.clone()\n",
        "\n",
        "        # Generate trajectory by iterating through the diffusion process\n",
        "        for i, t in enumerate(self.scheduler.timesteps):\n",
        "            # Get model prediction\n",
        "            with torch.no_grad():\n",
        "                pred_noise = self.model(latent, t).sample\n",
        "\n",
        "            # Step the scheduler to get the next latent\n",
        "            scheduler_output = self.scheduler.step(pred_noise, t, latent)\n",
        "            prev_sample = scheduler_output.prev_sample\n",
        "\n",
        "            # Create step\n",
        "            step = DiffusionStep(\n",
        "                timestep=t,\n",
        "                current_sample=latent.clone(),  # Current latent (Xt)\n",
        "                prev_sample=prev_sample.clone(),  # Next latent in the trajectory (Xt-1)\n",
        "                pred_noise=pred_noise,\n",
        "                log_prob=None,\n",
        "                mean=None,\n",
        "                variance=None\n",
        "            )\n",
        "            steps.append(step)\n",
        "\n",
        "            # Compute log probability\n",
        "            step.log_prob, step.mean, step.variance = step.compute_log_prob(self.model, self.scheduler)\n",
        "            step.log_prob = step.log_prob.detach()\n",
        "            step.mean = step.mean.detach()\n",
        "            step.variance = step.variance.detach()\n",
        "\n",
        "            # Move to the next step\n",
        "            latent = prev_sample\n",
        "\n",
        "        return steps\n",
        "\n",
        "    def __iter__(self) -> Iterator[DiffusionStep]:\n",
        "        \"\"\"Allow iteration over trajectory steps.\"\"\"\n",
        "        return iter(self.steps)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return the number of steps in the trajectory.\"\"\"\n",
        "        return len(self.steps)\n",
        "\n",
        "    def __getitem__(self, idx) -> DiffusionStep:\n",
        "        \"\"\"Get a specific step by index.\"\"\"\n",
        "        return self.steps[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZpm-2CNUZ1U"
      },
      "source": [
        "# Reward model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H3-EObsrUb9e"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def gender_reward(img_tensor):\n",
        "\n",
        "  pipe = pipeline(\"image-classification\", model=\"rizvandwiki/gender-classification\")\n",
        "\n",
        "  image_processed = img_tensor.cpu().permute(0, 2, 3, 1)\n",
        "  image_processed = (image_processed + 1.0) * 127.5\n",
        "  image_processed = image_processed.numpy().astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image_processed[0])\n",
        "\n",
        "  classification = pipe(image)\n",
        "  for class_pred in classification:\n",
        "    if class_pred[\"label\"] == \"male\":\n",
        "      if class_pred[\"score\"] >= 0.5:\n",
        "        return class_pred[\"score\"]*2\n",
        "      else:\n",
        "        return class_pred[\"score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvnhd6XOtXbR"
      },
      "source": [
        "# Analyze trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8Y9OuwbAXNx"
      },
      "outputs": [],
      "source": [
        "trajectories_val = []\n",
        "total_reward = 0\n",
        "for _ in range(2):\n",
        "  trajectories_val.append(Trajectory(model, scheduler, device, num_inference_steps=50))\n",
        "  reward = gender_reward(trajectories_val[-1][-1].prev_sample)\n",
        "  total_reward += reward\n",
        "  display_sample(trajectories_val[-1][-1].prev_sample)\n",
        "print(f\"Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0KTVOWFx4aq"
      },
      "outputs": [],
      "source": [
        "asdict(trajectories_val[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-ZEpBFet-nh"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "for step in trajectories_val[0]:\n",
        "  if step.timestep%100 == 0:\n",
        "    display_sample(step.prev_sample, f\"Timestep {step.timestep}\")\n",
        "    time.sleep(2)\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-FiuTWBGOWv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Prepare data for visualization\n",
        "all_timesteps = []\n",
        "all_log_probs = []\n",
        "\n",
        "# Extract timesteps and log probabilities from trajectories\n",
        "for i, trajectory in enumerate(trajectories_val[:3]):\n",
        "  timesteps = []\n",
        "  log_probs = []\n",
        "  for step in trajectory:\n",
        "    timesteps.append(step.timestep.item() if torch.is_tensor(step.timestep) else step.timestep)\n",
        "    log_probs.append(step.log_prob.item())\n",
        "\n",
        "  all_timesteps.append(timesteps)\n",
        "  all_log_probs.append(log_probs)\n",
        "\n",
        "# Plot individual trajectories\n",
        "for i in range(len(all_timesteps)):\n",
        "  plt.plot(all_timesteps[i], all_log_probs[i], label=f'Trajectory {i+1}', alpha=0.7)\n",
        "\n",
        "plt.title('Log Probabilities Across Timesteps (Individual Trajectories)')\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Log Probability')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYh9ae5l0Jp5"
      },
      "source": [
        "# Fine-tune with REINFORCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KTOD3b1CKGtf"
      },
      "outputs": [],
      "source": [
        "def get_gradient_norm(model):\n",
        "    total_norm = 0.0\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            param_norm = param.grad.detach().data.norm(2)  # L2 norm\n",
        "            total_norm += param_norm.item() ** 2\n",
        "    return total_norm ** 0.5  # Square root to get final norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vGE5RSNA4mBZ"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(model, scheduler, device, prompts, batch_size, group_size):\n",
        "    \"\"\"\n",
        "    The final dataset will have (prompts x group_size) trajectories.\n",
        "    The shape will be (n_batches, batch_size (same as n_groups_per_batch), group_size).\n",
        "    The last batch can have fewer groups if the number of prompts is not divisible by batch_size.\n",
        "    \"\"\"\n",
        "    steps_dataset = []\n",
        "\n",
        "    # Iterate over prompts in chunks of batch_size\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = []\n",
        "        for prompt in prompts[i:i + batch_size]:\n",
        "            group = [Trajectory(model, scheduler, device, num_inference_steps=50) for _ in range(group_size)]\n",
        "            batch.append(group)\n",
        "        steps_dataset.append(batch)\n",
        "\n",
        "    return steps_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CkPf-7JjzeHS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from dataclasses import dataclass, asdict\n",
        "import pandas as pd\n",
        "\n",
        "def train_with_reinforce(model, scheduler, dataset, train_epochs=5, lr=1e-6):\n",
        "    updated_model = model\n",
        "    updated_model.train()\n",
        "    optimizer = torch.optim.AdamW(updated_model.parameters(), lr=lr)\n",
        "\n",
        "    # Logging data\n",
        "    log_data = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(train_epochs):\n",
        "        total_loss = 0\n",
        "        total_reward = 0\n",
        "        for batch_idx, batch in enumerate(dataset):\n",
        "            n_trajectories = len(batch)*len(batch[0])\n",
        "            for group_idx, group in enumerate(batch):\n",
        "              trajectories = group\n",
        "              # Get advantages of each trajectory in the group\n",
        "              rewards = [gender_reward(trajectory[-1].prev_sample) for trajectory in trajectories]\n",
        "              print(\"Rewards: \", rewards)\n",
        "              total_reward += sum(rewards)\n",
        "              if max(rewards) < 0.5: # No men\n",
        "                print(\"Skipping group\")\n",
        "                n_trajectories -= len(group)\n",
        "                continue\n",
        "\n",
        "              group_mean = torch.tensor(rewards).mean()\n",
        "              group_std = (torch.tensor(rewards).std()+1e-5)\n",
        "              advantages = [(reward-group_mean)/group_std for reward in rewards]\n",
        "              print(\"Advantages: \", advantages)\n",
        "\n",
        "              # Process each trajectory\n",
        "              for i, trajectory in enumerate(trajectories):\n",
        "                  sample_prob = 0.0\n",
        "                  for step_idx, step in enumerate(trajectory[30:40]):\n",
        "                    log_prob_new, mean, var = step.compute_log_prob(updated_model, trajectory.scheduler)\n",
        "\n",
        "                    # Importance Sampling Ratio (exp(log(p_new/p_old)) = exp(log_p_new - log_p_old))\n",
        "                    importance_ratio = torch.exp(log_prob_new - step.log_prob)\n",
        "\n",
        "                    # Advantage\n",
        "                    advantage = advantages[i]\n",
        "\n",
        "                    # PPO clipping\n",
        "                    clipped_ratio = torch.clamp(importance_ratio, 1 - 1e-4, 1 + 1e-4)\n",
        "                    loss_clip = torch.min(importance_ratio * advantage, clipped_ratio * advantage)\n",
        "                    #print(f\"Importance ratio = {importance_ratio} | Clipped ratio = {clipped_ratio}\")\n",
        "\n",
        "                    # KL regularization\n",
        "                    kl = torch.distributions.kl_divergence(\n",
        "                        torch.distributions.Normal(step.mean, torch.sqrt(step.variance)),\n",
        "                        torch.distributions.Normal(mean, torch.sqrt(var))\n",
        "                    )\n",
        "                    kl = kl.mean(dim=list(range(1, len(kl.shape))))\n",
        "\n",
        "                    # Compute the loss\n",
        "                    loss_base = -1*loss_clip + 0.0*kl\n",
        "                    loss_total = loss_base.view(loss_base.size(0), -1).sum(dim=1).mean()\n",
        "                    # Average across trajectories\n",
        "                    loss_total = loss_total/n_trajectories\n",
        "                    loss_total.backward()\n",
        "                    sample_prob += log_prob_new.item()\n",
        "                    # if get_gradient_norm(updated_model) == 0:\n",
        "                    #   print(\"Gradient norm: \", get_gradient_norm(updated_model))\n",
        "\n",
        "                    # Log metrics\n",
        "                    log_data.append({\n",
        "                        \"epoch\": epoch,\n",
        "                        \"batch\": batch_idx,\n",
        "                        \"group\": group_idx,\n",
        "                        \"sample\": i,\n",
        "                        \"step\": step_idx,\n",
        "                        \"log_prob_new\": log_prob_new.item(),\n",
        "                        \"log_prob_old\": step.log_prob.item(),\n",
        "                        \"importance_ratio\": importance_ratio.item(),\n",
        "                        \"clipped_ratio\": clipped_ratio.item(),\n",
        "                        \"kl_loss\": kl.item(),\n",
        "                        \"reward\": rewards[i],\n",
        "                        \"advantage\": advantage.item(),\n",
        "                        \"loss_clip\": loss_clip.item(),\n",
        "                        \"loss_base\": loss_base.item(),\n",
        "                        \"loss_total\": loss_total.item(),\n",
        "                        \"gradient\": get_gradient_norm(updated_model)\n",
        "                    })\n",
        "\n",
        "                  display_sample(trajectory[-1].prev_sample, label = f\"Advantage = {advantage} | Total Log prob = {sample_prob}\")\n",
        "                  total_loss += sample_prob\n",
        "\n",
        "            # Update the model\n",
        "            #torch.nn.utils.clip_grad_norm_(updated_model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        print(f\"Epoch reward: {total_reward}\")\n",
        "\n",
        "    # Convert log data to DataFrame\n",
        "    log_df = pd.DataFrame(log_data)\n",
        "\n",
        "    return updated_model, log_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ym0f9ucF0-JS"
      },
      "outputs": [],
      "source": [
        "full_epochs = 5 # Each full epoch include sampling + training # 2/2\n",
        "train_epochs = 5 # Specifies how many times the model iterates over the same sampled trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OxQB0QKU2x_l",
        "outputId": "98323e13-81b5-43f9-a68b-95837f6fb2b5"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model = copy.deepcopy(pretrained_model).to(device)\n",
        "dfs =[]\n",
        "for i in range(full_epochs):\n",
        "  # Generate dataset of trajectories (n_batches, n_groups_per_batch (batch_size), group_size)\n",
        "  print(f\"{20*'-*'} Full epoch {i} {20*'-*'}\")\n",
        "  dataset = generate_dataset(model=model,\n",
        "                             scheduler=scheduler,\n",
        "                             device=device,\n",
        "                             prompts = 4*[None],\n",
        "                             batch_size=1,\n",
        "                             group_size=5)\n",
        "  model, df = train_with_reinforce(model, scheduler, dataset, train_epochs, lr=1e-6)\n",
        "  dfs.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uk3QTSLnuC9U"
      },
      "outputs": [],
      "source": [
        "filename = \"reinforce_log_10_sampling_5_epochs_4_prompts_steps_30_40.csv\"\n",
        "for i in range(len(dfs)):\n",
        "  dfs[i][\"sampling_epoch\"] = i\n",
        "concated_df = pd.concat(dfs)\n",
        "concated_df.to_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RPvWcagABwWm",
        "outputId": "80d2aaf0-cb8d-4dd8-e92e-74624d7a7d08"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7FzOQ0xobrA",
        "outputId": "478d0b61-bd9a-4566-8105-4112e86ea15f"
      },
      "outputs": [],
      "source": [
        "for b in dataset:\n",
        "  for g in b:\n",
        "    for t in g:\n",
        "      print(t[-8].log_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QHQTDuEA31TX",
        "outputId": "6bae3ef2-0862-43ee-cca2-5ff2af4c3bc9"
      },
      "outputs": [],
      "source": [
        "total_reward = 0\n",
        "for _ in range(50):\n",
        "  trajectorie = Trajectory(model, scheduler, device, num_inference_steps=50)\n",
        "  reward = gender_reward(trajectorie[-1].prev_sample)\n",
        "  total_reward += reward\n",
        "  display_sample(trajectorie[-1].prev_sample, label=f\"Reward = {reward}\")\n",
        "print(f\"Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Y0W1SOA2OrD",
        "outputId": "2bb5663b-aa1f-4fe5-fbfb-9c37817b74fb"
      },
      "outputs": [],
      "source": [
        "total_reward = 0\n",
        "for _ in range(50):\n",
        "  trajectorie_ref = Trajectory(pretrained_model, scheduler, device, num_inference_steps=50)\n",
        "  reward = gender_reward(trajectorie_ref[-1].prev_sample)\n",
        "  total_reward += reward\n",
        "  display_sample(trajectorie_ref[-1].prev_sample, label=f\"Reward = {reward}\")\n",
        "print(f\"Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "zf03J2ZE7j2p",
        "outputId": "2cf4798f-63fd-414f-e8ca-11024a5c596a"
      },
      "outputs": [],
      "source": [
        "concated_df.groupby(\"sampling_epoch\")[\"epoch\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "-Z0WeAEHKiX6",
        "outputId": "9f123adc-834a-4930-9b08-b6f82c84fb8c"
      },
      "outputs": [],
      "source": [
        "concated_df.groupby(\"sampling_epoch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hT3NJnBT6uS"
      },
      "source": [
        "Investigate impact of each interval of timesteps\n",
        "If importance ragio is clipped, it is infficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "IH3ewgXFQChj",
        "outputId": "d6d60582-3c95-4887-a91f-e229a1c08e94"
      },
      "outputs": [],
      "source": [
        "concated_df[\"batch\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkhOPQQPK1yk",
        "outputId": "8b0efcce-d73a-41de-e9b9-8d6410fb8c3c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np  # Needed for np.where()\n",
        "\n",
        "# Assign 'reward_sign' based on whether 'advantage' is positive or not\n",
        "concated_df['reward_sign'] = np.where(concated_df[\"advantage\"] > 0, \"positive\", \"negative\")\n",
        "\n",
        "# Group by epoch and reward sign, then calculate the mean of 'loss_total'\n",
        "loss_by_epoch_and_reward = concated_df.groupby(['sampling_epoch', 'epoch', 'reward_sign'])['loss_total'].mean().reset_index()\n",
        "\n",
        "# Display the results\n",
        "print(loss_by_epoch_and_reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "A3tOcPxdPYMy",
        "outputId": "fc98dd09-baa3-495b-a02c-3ff8bb8dc431"
      },
      "outputs": [],
      "source": [
        "concated_df.groupby(['sampling_epoch', 'epoch', 'batch', 'sample']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6PM8qi8YIL",
        "outputId": "a74e6ef5-66d7-4454-c9bb-dd3a732a5200"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"image-classification\", model=\"rizvandwiki/gender-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi30E6qrCtbK"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def gender_reward_test(img_tensor):\n",
        "\n",
        "  pipe = pipeline(\"image-classification\", model=\"rizvandwiki/gender-classification\")\n",
        "\n",
        "  image_processed = img_tensor.cpu().permute(0, 2, 3, 1)\n",
        "  image_processed = (image_processed + 1.0) * 127.5\n",
        "  image_processed = image_processed.numpy().astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image_processed[0])\n",
        "\n",
        "  classification = pipe(image)\n",
        "  print(classification)\n",
        "  for class_pred in classification:\n",
        "    if class_pred[\"label\"] == \"male\":\n",
        "      if class_pred[\"score\"] >= 0.7:\n",
        "        return class_pred[\"score\"]*2\n",
        "      else:\n",
        "        return class_pred[\"score\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "34xA3BGbCzpH",
        "outputId": "1037981f-7ed9-4e3b-9139-612a34471626"
      },
      "outputs": [],
      "source": [
        "for batch_idx, batch in enumerate(dataset):\n",
        "  for group_idx, group in enumerate(batch):\n",
        "    for i, trajectory in enumerate(group):\n",
        "      print(gender_reward_test(trajectory[-1].prev_sample))\n",
        "      display_sample(trajectory[-1].prev_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGuXWtldx0sE"
      },
      "outputs": [],
      "source": [
        "sampling_1 = dfs[0]\n",
        "sampling_2 = dfs[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FrHyN8GpyJbG",
        "outputId": "4a88abdd-1180-4875-8158-ee2a41a26f1d"
      },
      "outputs": [],
      "source": [
        "sampling_1.groupby(\"epoch\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "oFikAb0TzAle",
        "outputId": "31f7d4df-3aba-4289-a99b-bc29f5e71415"
      },
      "outputs": [],
      "source": [
        "sampling_2.groupby(\"epoch\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe1It6fzDOTI"
      },
      "source": [
        "To do:\n",
        "- Check loss of reference trajectories over the iterations. I expect the loss of male samples to decrease and the loss of female samples to increase. Since the trajectories will be fixed and neither importance sampling nor regularization is being used, maybe the loss can increase at some point as the updated model diverges from the original\n",
        "- Batches\n",
        "- Advantages ok\n",
        "- PPO ok\n",
        "- KL\n",
        "- Gradient norm\n",
        "- What about sampling the timesteps as Pinterest paper?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6sgi-1xww6Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tc5rnl6WtR_b",
        "fAHvdlMRtPiH",
        "zox6jZlttI34",
        "AZpm-2CNUZ1U",
        "Hvnhd6XOtXbR"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
